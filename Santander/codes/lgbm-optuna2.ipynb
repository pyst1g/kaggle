{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://www.kaggle.com/ruby33421/lgbm-with-new-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93d7b4b8f5f6e5289cfc0312d650744e64905bc7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Intro\n",
    "Please see Alexey Pronin's kernel (https://www.kaggle.com/graf10a/logistic-regression-with-new-features-feather) to read more on feature engineering and the performance benefit of using feather files.\n",
    "Alexey Pronin's kernel also references Youri Matiounine's work here: (https://www.kaggle.com/ymatioun/santander-linear-model-with-additional-features) \n",
    "\n",
    "The featuring engineering process adds 1000 new features, which means a total of 1200 features for the Santander dataset. The original kernel uses a simple logistic regression for training, which achieves a very good score of 0.896 (AUC). This kernel will use Light GBM model, but instead of using incorporating all the 1K additional features in our model, we will use feature importance to select some of the top engineered features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "319c9748ad2d9b82cc875000f58afa2129aeb9c3"
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "import gc\n",
    "import keras\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import time\n",
    "# import shutil\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from functools import partial\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from numpy import sort\n",
    "from pprint import pprint\n",
    "from pylab import rcParams\n",
    "from scipy.stats import norm, rankdata\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#csvデータの呼び出し場所\n",
    "loadpath = \"../input/\"\n",
    "#csvデータの保存場所\n",
    "savepath = \"../output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31a0c430046df842333652c410b3181d800f0551"
   },
   "source": [
    "Now, let's read the CSV files containing the training and testing data and measure how long it takes.\n",
    "\n",
    "Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d080b4a0bf27808a316196c71948a96280ef177"
   },
   "outputs": [],
   "source": [
    "path_train = '../input/train.feather'\n",
    "path_test = '../input/test.feather'\n",
    "\n",
    "print(\"Reading train data...\")\n",
    "start = time.time()\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"It takes {0:.2f} seconds to read 'train.csv'.\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e6904f34859901e764adde45ed0bb3bc13e4f58"
   },
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "0fca1a0b7f595147cc5c3641b1a45c9d7f8e2340",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-55b84167a283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading test data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Reading test data...\")\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"It takes {0:.2f} seconds to read 'test.csv'.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "733bef277c96bbdec20afcbd9c2009865ea863f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (200000, 202)\n",
      "Test:  (200000, 201)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \",train.shape)\n",
    "print(\"Test: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c74d587203855a0a8eb7da6b2f6abb3090bb60d"
   },
   "source": [
    "Saving the 'target' and 'ID_code' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "74a87959eb66d371c314180f4877d1afdde136b7"
   },
   "outputs": [],
   "source": [
    "target = train.pop('target')\n",
    "train_ids = train.pop('ID_code')\n",
    "test_ids = test.pop('ID_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c2c537288b4915a1f860065a2046e47cae19459"
   },
   "source": [
    "Saving the number of rows in 'train' for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "b1026519541d70d9206f9941fc29d19005fa1dcd"
   },
   "outputs": [],
   "source": [
    "len_train = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af2947142503c41f3c26e9c805e14e033fceb955"
   },
   "source": [
    "Merging test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "fc7bb057b85c4a8b12b102e7432e261ff6a92954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 200)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.concat([train, test])\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b29b8bd47b43d76ee650e12e063c34c3c1ad189"
   },
   "source": [
    "Removing data we no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "_uuid": "bca8a00d9d62f3a4479c524b66d6e906ac155b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55788"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test, train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef8301089d9bfd8880ad0165e3d1c248a5fb1fde"
   },
   "source": [
    "Saving the list of original features in a new list `original_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "_uuid": "134f8d281a4fafdbbbd51fb3429015d271d895ac"
   },
   "outputs": [],
   "source": [
    "original_features = merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c759bfea1d90b899118ed5a153a0189ea10d7a6c"
   },
   "source": [
    "## Computing new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "06df646dee338e944955dd6059df57cd6c73afa0"
   },
   "outputs": [],
   "source": [
    "for col in merged.columns:\n",
    "    # Normalize the data, so that it can be used in norm.cdf(), \n",
    "    # as though it is a standard normal variable\n",
    "    merged[col] = ((merged[col] - merged[col].mean()) \n",
    "    / merged[col].std()).astype('float32')\n",
    "\n",
    "    # Square\n",
    "    merged[col+'^2'] = merged[col] * merged[col]\n",
    "\n",
    "    # Cube\n",
    "    merged[col+'^3'] = merged[col] * merged[col] * merged[col]\n",
    "\n",
    "    # 4th power\n",
    "    merged[col+'^4'] = merged[col] * merged[col] * merged[col] * merged[col]\n",
    "\n",
    "    # Cumulative percentile (not normalized)\n",
    "    merged[col+'_cp'] = rankdata(merged[col]).astype('float32')\n",
    "\n",
    "    # Cumulative normal percentile\n",
    "    merged[col+'_cnp'] = norm.cdf(merged[col]).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5fd487e4440606deb9e936346e982513f0718c9"
   },
   "source": [
    "Getting the list of names of the added features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "456a64b4d2c1ada1b6db546a1d004537df4bd238"
   },
   "outputs": [],
   "source": [
    "new_features = set(merged.columns) - set(original_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8188eb856e421905972cc6f34ab4b43e87dd41f8"
   },
   "source": [
    "Normalize the data. Again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "7180731459fe9ce60f95b94b77f3d7f9a565823d"
   },
   "outputs": [],
   "source": [
    "for col in new_features:\n",
    "    merged[col] = ((merged[col] - merged[col].mean()) \n",
    "    / merged[col].std()).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f1039a0b002c1db092a9b3d590759531facc3e6"
   },
   "source": [
    "Saving the data to feather files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "9f04f23ad704daa0207a03c9c6e5d680ac0caed8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing target to a feather files...\n",
      "Writing train_ids to a feather files...\n",
      "Writing test_ids to a feather files...\n",
      "Writing train to a feather files...\n",
      "Writing test to a feather files...\n"
     ]
    }
   ],
   "source": [
    "path_target = loadpath + 'target.feather'\n",
    "\n",
    "path_train_ids =loadpath + 'train_ids_extra_features.feather'\n",
    "path_test_ids = loadpath + 'test_ids_extra_features.feather'\n",
    "\n",
    "path_train = loadpath + 'train_extra_features.feather'\n",
    "path_test = loadpath + 'test_extra_features.feather'\n",
    "\n",
    "print(\"Writing target to a feather files...\")\n",
    "pd.DataFrame({'target' : target.values}).to_feather(path_target)\n",
    "\n",
    "print(\"Writing train_ids to a feather files...\")\n",
    "pd.DataFrame({'ID_code' : train_ids.values}).to_feather(path_train_ids)\n",
    "\n",
    "print(\"Writing test_ids to a feather files...\")\n",
    "pd.DataFrame({'ID_code' : test_ids.values}).to_feather(path_test_ids)\n",
    "\n",
    "print(\"Writing train to a feather files...\")\n",
    "feather.write_dataframe(merged.iloc[:len_train], path_train)\n",
    "\n",
    "print(\"Writing test to a feather files...\")\n",
    "feather.write_dataframe(merged.iloc[len_train:], path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "640948a1a36e2d3d73f18ceb9cfb816be6d11d7b"
   },
   "source": [
    "Removing data we no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del target, train_ids, test_ids, merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "837f988316528d5c3d4530043448fe5849be3fa5"
   },
   "source": [
    "## Loading the data from feather files\n",
    "\n",
    "Now let's load of these data back into memory. This will help us to illustrate the advantage of using the feather file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "60b26db1cf85167b14f9223af995a8656bdaa316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading target\n",
      "0.005985 sec\n"
     ]
    }
   ],
   "source": [
    "path_target = loadpath + 'target.feather'\n",
    "\n",
    "path_train_ids = loadpath + 'train_ids_extra_features.feather'\n",
    "path_test_ids = loadpath + 'test_ids_extra_features.feather'\n",
    "\n",
    "path_train = loadpath + 'train_extra_features.feather'\n",
    "path_test = loadpath + 'test_extra_features.feather'\n",
    "\n",
    "print(\"Reading target\")\n",
    "start = time.time()\n",
    "y = feather.read_dataframe(path_target).values.ravel()\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2f60516cb907e9e62f97eb99ebb00db079edc6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train_ids\n",
      "0.047362 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading train_ids\")\n",
    "start = time.time()\n",
    "train_ids = feather.read_dataframe(path_train_ids).values.ravel()\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "4c8ad8191f0a4cd976645e7d7b59f7c16c48311f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test_ids\n",
      "0.048272 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading test_ids\")\n",
    "start = time.time()\n",
    "test_ids = feather.read_dataframe(path_test_ids).values.ravel()\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "afe5ba0c48d46a05e09c2de00b094a5a479fded6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data\n",
      "0.135424 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading training data\")\n",
    "\n",
    "start = time.time()\n",
    "train_logistic = feather.read_dataframe(path_train)\n",
    "train = train_logistic.iloc[:,:200]\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4764997b330eb79e2962c6ea207b2bf43d75b7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing data\n",
      "0.131395 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading testing data\")\n",
    "\n",
    "start = time.time()\n",
    "test_logistic = feather.read_dataframe(path_test)\n",
    "test = test_logistic.iloc[:,:200]\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "8c278ce260046cb0adfa633f557cf97fa63f2e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  200\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of features: \",train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3d1c00f01bdcc40525a6d59cf3bc463bdbcef11"
   },
   "source": [
    "Hopefully now you can see the great advantage of using the feather files: it is blazing fast. Just compare the timings shown above with those measured for the original CSV files: the processed data sets (stored in the feather file format) that we have just loaded are much bigger in size that the original ones (stored in the CSV files) but we can load them in almost no time!\n",
    "\n",
    "# Logistic regession with the added features.\n",
    "\n",
    "Now let's finally do some modeling! More specifically, we will build a straighforward logistic regression model to see whether or not we can improve on linear regression result (LB 0.894). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "72ddd6eee811099caba7f2cc610e7f099d8fa84f"
   },
   "outputs": [],
   "source": [
    "NFOLDS = 10\n",
    "RANDOM_STATE = 823\n",
    "\n",
    "feature_list = train_logistic.columns\n",
    "\n",
    "# test = test[feature_list]\n",
    "\n",
    "# X = train.values.astype(float)\n",
    "# X_test = test.values.astype(float)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "                        random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 0\n",
      "AUC = 0.8867748850235262\n",
      "Current Fold: 1\n",
      "AUC = 0.9077794663852814\n",
      "Current Fold: 2\n",
      "AUC = 0.905253941520856\n",
      "Current Fold: 3\n",
      "AUC = 0.8912520222677607\n",
      "Current Fold: 4\n",
      "AUC = 0.89269715900763\n",
      "Current Fold: 5\n",
      "AUC = 0.8970970605560303\n",
      "Current Fold: 6\n",
      "AUC = 0.9029870104729272\n",
      "Current Fold: 7\n",
      "AUC = 0.8989451851360208\n",
      "Current Fold: 8\n",
      "AUC = 0.899775607786526\n",
      "Current Fold: 9\n",
      "AUC = 0.9002646578115537\n",
      "Current Fold: 10\n",
      "AUC = 0.9005251673815469\n",
      "Current Fold: 11\n",
      "AUC = 0.9004905433919894\n",
      "Current Fold: 12\n",
      "AUC = 0.8970716180077932\n",
      "Current Fold: 13\n",
      "AUC = 0.8953268122976004\n",
      "Current Fold: 14\n",
      "AUC = 0.8999129975470066\n",
      "Current Fold: 15\n",
      "AUC = 0.8937476043904989\n",
      "Current Fold: 16\n",
      "AUC = 0.8953758168579007\n",
      "Current Fold: 17\n",
      "AUC = 0.8945592216792636\n",
      "Current Fold: 18\n",
      "AUC = 0.9018440966539624\n",
      "Current Fold: 19\n",
      "AUC = 0.8896115371753676\n"
     ]
    }
   ],
   "source": [
    "oof_preds = np.zeros((len(train_logistic), 1))\n",
    "test_preds = np.zeros((len(test_logistic), 1))\n",
    "roc_cv =[]\n",
    "\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    print(\"Current Fold: {}\".format(fold_))\n",
    "    trn_x, trn_y = train_logistic.iloc[trn_, :], y[trn_]\n",
    "    val_x, val_y = train_logistic.iloc[val_, :], y[val_]\n",
    "    \n",
    "    clf =  LogisticRegression(solver='lbfgs', max_iter=1500, C=10)\n",
    "\n",
    "    clf.fit(trn_x, trn_y)\n",
    "\n",
    "    val_pred = clf.predict_proba(val_x)[:,1]\n",
    "    test_fold_pred = clf.predict_proba(test_logistic)[:,1]\n",
    "    \n",
    "    roc_cv.append(roc_auc_score(val_y, val_pred))\n",
    "    \n",
    "    print(\"AUC = {}\".format(roc_auc_score(val_y, val_pred)))\n",
    "    oof_preds[val_, :] = val_pred.reshape((-1, 1))\n",
    "    test_preds += test_fold_pred.reshape((-1, 1))\n",
    "test_preds/=NFOLDS\n",
    "test_preds = test_preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1200)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logistic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1500, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf =  LogisticRegression(solver='lbfgs', max_iter=1500, C=10)\n",
    "clf.fit(train_logistic,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foldしないでテスト予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_single = clf.predict_proba(test_logistic)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foldでやったやつとの差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.932710383915044"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(test_preds_single - test_preds).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de1e4b00f84f8299f1eeff9f09e63e6299add289"
   },
   "source": [
    "### Feature Importance & Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "6df10f59e9448863064fddd4312961ddbe243f20"
   },
   "outputs": [],
   "source": [
    "feature_importance = abs(clf.coef_[0])\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "bca957e6843f437ec776670c613e0da3280f28ed"
   },
   "outputs": [],
   "source": [
    "top_new_features = feature_list[sorted_idx[0:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ec76bf256250c72a45ad81a6c28134e47088ed2f"
   },
   "outputs": [],
   "source": [
    "train_newf = train_logistic[top_new_features]\n",
    "Orig_feature_list = list(original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "229583d56728e9a1a98ce539f4ff9bcc6b549f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [col for col in train_newf.columns if col not in Orig_feature_list]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "132fd0efaf0adf943b038720f8f1062c319aafd3"
   },
   "outputs": [],
   "source": [
    "# train2 = pd.concat([train[original_features], train[cols]], axis=1)\n",
    "# test2 = test[train2.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb198e54be7b7da392a35c0db059741e0db49149"
   },
   "source": [
    "## LGBM model with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "d176ad7c3da9dc712e3abf6f57ce7271ea7e7a94"
   },
   "outputs": [],
   "source": [
    "params_tuned ={\n",
    "    'max_leaves': 962,\n",
    "    'min_data_in_leaf': 101,\n",
    "    'learning_rate': 0.008467089868304085,\n",
    "    'bagging_fraction': 0.39421465183790383,\n",
    "    'feature_fraction': 0.742029399864705,\n",
    "    'reg_alpha': 0.1659749229798302, \n",
    "    'reg_lambda': 1.4223979160695897, \n",
    "    'colsample_bytree': 0.7931590791796129,\n",
    "    'min_gain_to_split': 0.06117879704656666, \n",
    "    'min_child_weight': 0.016977338542881623,\n",
    "}\n",
    "\n",
    "params_tuned.update({\n",
    "    'boosting': 'gbdt',\n",
    "    'bagging_freq': 5, \n",
    "    'num_threads': 4,\n",
    "    'objective': 'binary',\n",
    "    'random_state': 823,\n",
    "    'metric': 'auc',\n",
    "    'verbosity': -1,\n",
    "})\n",
    "\n",
    "# {'num_leaves': 9,\n",
    "#          'min_data_in_leaf': 42,\n",
    "#          'objective': 'binary',\n",
    "#          'max_depth': 11,\n",
    "#          'learning_rate': 0.03,\n",
    "#          'boosting': 'gbdt',\n",
    "# #          'bagging_freq': 5,\n",
    "#          'bagging_fraction': 0.8,\n",
    "#          'feature_fraction': 0.8201,\n",
    "#          'bagging_seed': 11,\n",
    "#          'reg_alpha': 3,\n",
    "#          'reg_lambda': 5,\n",
    "#          'random_state': 42,\n",
    "#          'metric': 'auc',\n",
    "#          'verbosity': -1,\n",
    "#          'colsample_bytree': 0.7,\n",
    "# #         'subsample': 0.81,\n",
    "#          'min_gain_to_split': 0.02,\n",
    "# #         'min_child_weight': 19.428902804238373,\n",
    "#          'num_threads': 4,\n",
    "# #          'tree_learner': 'data'\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat Mar 16 14:45:39 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.859574\tvalid_1's auc: 0.830581\n",
      "[600]\ttraining's auc: 0.894037\tvalid_1's auc: 0.861971\n",
      "[900]\ttraining's auc: 0.911017\tvalid_1's auc: 0.875216\n",
      "[1200]\ttraining's auc: 0.922601\tvalid_1's auc: 0.883683\n",
      "[1500]\ttraining's auc: 0.930889\tvalid_1's auc: 0.888404\n",
      "[1800]\ttraining's auc: 0.937147\tvalid_1's auc: 0.891889\n",
      "[2100]\ttraining's auc: 0.942196\tvalid_1's auc: 0.894442\n",
      "[2400]\ttraining's auc: 0.946532\tvalid_1's auc: 0.895984\n",
      "[2700]\ttraining's auc: 0.950185\tvalid_1's auc: 0.897266\n",
      "[3000]\ttraining's auc: 0.953687\tvalid_1's auc: 0.898099\n",
      "[3300]\ttraining's auc: 0.956812\tvalid_1's auc: 0.898618\n",
      "[3600]\ttraining's auc: 0.959748\tvalid_1's auc: 0.899059\n",
      "[3900]\ttraining's auc: 0.9625\tvalid_1's auc: 0.899253\n",
      "[4200]\ttraining's auc: 0.965139\tvalid_1's auc: 0.899437\n",
      "[4500]\ttraining's auc: 0.967681\tvalid_1's auc: 0.899703\n",
      "Early stopping, best iteration is:\n",
      "[4540]\ttraining's auc: 0.96804\tvalid_1's auc: 0.899754\n",
      "AUC = 0.8997542441757086\n",
      "Fold 1 started at Sat Mar 16 14:48:34 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.860963\tvalid_1's auc: 0.832577\n",
      "[600]\ttraining's auc: 0.893992\tvalid_1's auc: 0.861123\n",
      "[900]\ttraining's auc: 0.911066\tvalid_1's auc: 0.874761\n",
      "[1200]\ttraining's auc: 0.922122\tvalid_1's auc: 0.882555\n",
      "[1500]\ttraining's auc: 0.930235\tvalid_1's auc: 0.887811\n",
      "[1800]\ttraining's auc: 0.9366\tvalid_1's auc: 0.891923\n",
      "[2100]\ttraining's auc: 0.941843\tvalid_1's auc: 0.894178\n",
      "[2400]\ttraining's auc: 0.94613\tvalid_1's auc: 0.895927\n",
      "[2700]\ttraining's auc: 0.94983\tvalid_1's auc: 0.897143\n",
      "[3000]\ttraining's auc: 0.953214\tvalid_1's auc: 0.898042\n",
      "[3300]\ttraining's auc: 0.956403\tvalid_1's auc: 0.898692\n",
      "[3600]\ttraining's auc: 0.959397\tvalid_1's auc: 0.898996\n",
      "[3900]\ttraining's auc: 0.962232\tvalid_1's auc: 0.899193\n",
      "[4200]\ttraining's auc: 0.964925\tvalid_1's auc: 0.899252\n",
      "[4500]\ttraining's auc: 0.967522\tvalid_1's auc: 0.899516\n",
      "[4800]\ttraining's auc: 0.969976\tvalid_1's auc: 0.899579\n",
      "Early stopping, best iteration is:\n",
      "[4761]\ttraining's auc: 0.969638\tvalid_1's auc: 0.89963\n",
      "AUC = 0.8996298314994977\n",
      "Fold 2 started at Sat Mar 16 14:51:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.860262\tvalid_1's auc: 0.843487\n",
      "[600]\ttraining's auc: 0.892948\tvalid_1's auc: 0.869119\n",
      "[900]\ttraining's auc: 0.910939\tvalid_1's auc: 0.881651\n",
      "[1200]\ttraining's auc: 0.922053\tvalid_1's auc: 0.888234\n",
      "[1500]\ttraining's auc: 0.930366\tvalid_1's auc: 0.892657\n",
      "[1800]\ttraining's auc: 0.936487\tvalid_1's auc: 0.895568\n",
      "[2100]\ttraining's auc: 0.941655\tvalid_1's auc: 0.897519\n",
      "[2400]\ttraining's auc: 0.946016\tvalid_1's auc: 0.898896\n",
      "[2700]\ttraining's auc: 0.949792\tvalid_1's auc: 0.899802\n",
      "[3000]\ttraining's auc: 0.953243\tvalid_1's auc: 0.900381\n",
      "[3300]\ttraining's auc: 0.956402\tvalid_1's auc: 0.900899\n",
      "[3600]\ttraining's auc: 0.959361\tvalid_1's auc: 0.901439\n",
      "[3900]\ttraining's auc: 0.962158\tvalid_1's auc: 0.901558\n",
      "[4200]\ttraining's auc: 0.964831\tvalid_1's auc: 0.901629\n",
      "[4500]\ttraining's auc: 0.967447\tvalid_1's auc: 0.901833\n",
      "Early stopping, best iteration is:\n",
      "[4486]\ttraining's auc: 0.967331\tvalid_1's auc: 0.901864\n",
      "AUC = 0.9018637772781452\n",
      "Fold 3 started at Sat Mar 16 14:54:28 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.86185\tvalid_1's auc: 0.832536\n",
      "[600]\ttraining's auc: 0.894112\tvalid_1's auc: 0.857889\n",
      "[900]\ttraining's auc: 0.911761\tvalid_1's auc: 0.87146\n",
      "[1200]\ttraining's auc: 0.923007\tvalid_1's auc: 0.879391\n",
      "[1500]\ttraining's auc: 0.931093\tvalid_1's auc: 0.88508\n",
      "[1800]\ttraining's auc: 0.937519\tvalid_1's auc: 0.888618\n",
      "[2100]\ttraining's auc: 0.94251\tvalid_1's auc: 0.891209\n",
      "[2400]\ttraining's auc: 0.946692\tvalid_1's auc: 0.893296\n",
      "[2700]\ttraining's auc: 0.950291\tvalid_1's auc: 0.894494\n",
      "[3000]\ttraining's auc: 0.95367\tvalid_1's auc: 0.89541\n",
      "[3300]\ttraining's auc: 0.956736\tvalid_1's auc: 0.895922\n",
      "[3600]\ttraining's auc: 0.959652\tvalid_1's auc: 0.89644\n",
      "[3900]\ttraining's auc: 0.962408\tvalid_1's auc: 0.896666\n",
      "[4200]\ttraining's auc: 0.965008\tvalid_1's auc: 0.896848\n",
      "[4500]\ttraining's auc: 0.967599\tvalid_1's auc: 0.897213\n",
      "[4800]\ttraining's auc: 0.970053\tvalid_1's auc: 0.897405\n",
      "[5100]\ttraining's auc: 0.972476\tvalid_1's auc: 0.897511\n",
      "Early stopping, best iteration is:\n",
      "[5050]\ttraining's auc: 0.972078\tvalid_1's auc: 0.897548\n",
      "AUC = 0.8975483339279146\n",
      "Fold 4 started at Sat Mar 16 14:57:38 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.860626\tvalid_1's auc: 0.829763\n",
      "[600]\ttraining's auc: 0.894126\tvalid_1's auc: 0.856919\n",
      "[900]\ttraining's auc: 0.911888\tvalid_1's auc: 0.870954\n",
      "[1200]\ttraining's auc: 0.922799\tvalid_1's auc: 0.878905\n",
      "[1500]\ttraining's auc: 0.930848\tvalid_1's auc: 0.88412\n",
      "[1800]\ttraining's auc: 0.937152\tvalid_1's auc: 0.887851\n",
      "[2100]\ttraining's auc: 0.942327\tvalid_1's auc: 0.890379\n",
      "[2400]\ttraining's auc: 0.946675\tvalid_1's auc: 0.892535\n",
      "[2700]\ttraining's auc: 0.950321\tvalid_1's auc: 0.893957\n",
      "[3000]\ttraining's auc: 0.953749\tvalid_1's auc: 0.894947\n",
      "[3300]\ttraining's auc: 0.956818\tvalid_1's auc: 0.895787\n",
      "[3600]\ttraining's auc: 0.959722\tvalid_1's auc: 0.895964\n",
      "[3900]\ttraining's auc: 0.962515\tvalid_1's auc: 0.896464\n",
      "[4200]\ttraining's auc: 0.965242\tvalid_1's auc: 0.896657\n",
      "[4500]\ttraining's auc: 0.96776\tvalid_1's auc: 0.897066\n",
      "Early stopping, best iteration is:\n",
      "[4585]\ttraining's auc: 0.968464\tvalid_1's auc: 0.897108\n",
      "AUC = 0.8971079289489183\n",
      "Fold 5 started at Sat Mar 16 15:00:34 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.860968\tvalid_1's auc: 0.831312\n",
      "[600]\ttraining's auc: 0.89393\tvalid_1's auc: 0.859071\n",
      "[900]\ttraining's auc: 0.911628\tvalid_1's auc: 0.872243\n",
      "[1200]\ttraining's auc: 0.922743\tvalid_1's auc: 0.880062\n",
      "[1500]\ttraining's auc: 0.930896\tvalid_1's auc: 0.88481\n",
      "[1800]\ttraining's auc: 0.937194\tvalid_1's auc: 0.888451\n",
      "[2100]\ttraining's auc: 0.942149\tvalid_1's auc: 0.890675\n",
      "[2400]\ttraining's auc: 0.94633\tvalid_1's auc: 0.892553\n",
      "[2700]\ttraining's auc: 0.950154\tvalid_1's auc: 0.893788\n",
      "[3000]\ttraining's auc: 0.953501\tvalid_1's auc: 0.894571\n",
      "[3300]\ttraining's auc: 0.956661\tvalid_1's auc: 0.894945\n",
      "[3600]\ttraining's auc: 0.959625\tvalid_1's auc: 0.895359\n",
      "[3900]\ttraining's auc: 0.962407\tvalid_1's auc: 0.895547\n",
      "[4200]\ttraining's auc: 0.965127\tvalid_1's auc: 0.895641\n",
      "[4500]\ttraining's auc: 0.967718\tvalid_1's auc: 0.895709\n",
      "[4800]\ttraining's auc: 0.970163\tvalid_1's auc: 0.895803\n",
      "[5100]\ttraining's auc: 0.972498\tvalid_1's auc: 0.895976\n",
      "Early stopping, best iteration is:\n",
      "[5093]\ttraining's auc: 0.972437\tvalid_1's auc: 0.895979\n",
      "AUC = 0.8959785840115708\n",
      "Fold 6 started at Sat Mar 16 15:03:47 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.861317\tvalid_1's auc: 0.83593\n",
      "[600]\ttraining's auc: 0.893609\tvalid_1's auc: 0.862425\n",
      "[900]\ttraining's auc: 0.911305\tvalid_1's auc: 0.874909\n",
      "[1200]\ttraining's auc: 0.922549\tvalid_1's auc: 0.882558\n",
      "[1500]\ttraining's auc: 0.930638\tvalid_1's auc: 0.887751\n",
      "[1800]\ttraining's auc: 0.937042\tvalid_1's auc: 0.891372\n",
      "[2100]\ttraining's auc: 0.942037\tvalid_1's auc: 0.893968\n",
      "[2400]\ttraining's auc: 0.946315\tvalid_1's auc: 0.895634\n",
      "[2700]\ttraining's auc: 0.950096\tvalid_1's auc: 0.896956\n",
      "[3000]\ttraining's auc: 0.953398\tvalid_1's auc: 0.8978\n",
      "[3300]\ttraining's auc: 0.956515\tvalid_1's auc: 0.898721\n",
      "[3600]\ttraining's auc: 0.959478\tvalid_1's auc: 0.899123\n",
      "[3900]\ttraining's auc: 0.962329\tvalid_1's auc: 0.89941\n",
      "[4200]\ttraining's auc: 0.964978\tvalid_1's auc: 0.899661\n",
      "[4500]\ttraining's auc: 0.967454\tvalid_1's auc: 0.900044\n",
      "[4800]\ttraining's auc: 0.969918\tvalid_1's auc: 0.900162\n",
      "[5100]\ttraining's auc: 0.97229\tvalid_1's auc: 0.900172\n",
      "Early stopping, best iteration is:\n",
      "[4965]\ttraining's auc: 0.971269\tvalid_1's auc: 0.900215\n",
      "AUC = 0.9002147682930539\n",
      "Fold 7 started at Sat Mar 16 15:06:55 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.862223\tvalid_1's auc: 0.828401\n",
      "[600]\ttraining's auc: 0.89439\tvalid_1's auc: 0.856729\n",
      "[900]\ttraining's auc: 0.911526\tvalid_1's auc: 0.870855\n",
      "[1200]\ttraining's auc: 0.922736\tvalid_1's auc: 0.879155\n",
      "[1500]\ttraining's auc: 0.930892\tvalid_1's auc: 0.88476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800]\ttraining's auc: 0.937126\tvalid_1's auc: 0.888783\n",
      "[2100]\ttraining's auc: 0.942145\tvalid_1's auc: 0.891264\n",
      "[2400]\ttraining's auc: 0.946344\tvalid_1's auc: 0.89327\n",
      "[2700]\ttraining's auc: 0.950076\tvalid_1's auc: 0.894485\n",
      "[3000]\ttraining's auc: 0.953422\tvalid_1's auc: 0.895496\n",
      "[3300]\ttraining's auc: 0.95661\tvalid_1's auc: 0.896301\n",
      "[3600]\ttraining's auc: 0.959614\tvalid_1's auc: 0.896695\n",
      "[3900]\ttraining's auc: 0.962382\tvalid_1's auc: 0.897049\n",
      "[4200]\ttraining's auc: 0.965037\tvalid_1's auc: 0.89731\n",
      "[4500]\ttraining's auc: 0.967569\tvalid_1's auc: 0.897456\n",
      "[4800]\ttraining's auc: 0.970091\tvalid_1's auc: 0.8977\n",
      "[5100]\ttraining's auc: 0.972396\tvalid_1's auc: 0.897807\n",
      "[5400]\ttraining's auc: 0.974611\tvalid_1's auc: 0.897848\n",
      "Early stopping, best iteration is:\n",
      "[5300]\ttraining's auc: 0.973898\tvalid_1's auc: 0.897919\n",
      "AUC = 0.8979186059695962\n",
      "Fold 8 started at Sat Mar 16 15:10:14 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.86076\tvalid_1's auc: 0.833235\n",
      "[600]\ttraining's auc: 0.89415\tvalid_1's auc: 0.860846\n",
      "[900]\ttraining's auc: 0.911437\tvalid_1's auc: 0.872977\n",
      "[1200]\ttraining's auc: 0.922713\tvalid_1's auc: 0.880155\n",
      "[1500]\ttraining's auc: 0.930875\tvalid_1's auc: 0.884742\n",
      "[1800]\ttraining's auc: 0.937183\tvalid_1's auc: 0.888055\n",
      "[2100]\ttraining's auc: 0.94223\tvalid_1's auc: 0.890264\n",
      "[2400]\ttraining's auc: 0.946423\tvalid_1's auc: 0.892086\n",
      "[2700]\ttraining's auc: 0.950187\tvalid_1's auc: 0.892736\n",
      "[3000]\ttraining's auc: 0.953536\tvalid_1's auc: 0.893148\n",
      "[3300]\ttraining's auc: 0.956647\tvalid_1's auc: 0.893813\n",
      "[3600]\ttraining's auc: 0.959628\tvalid_1's auc: 0.894051\n",
      "Early stopping, best iteration is:\n",
      "[3573]\ttraining's auc: 0.959364\tvalid_1's auc: 0.894125\n",
      "AUC = 0.8941248262750917\n",
      "Fold 9 started at Sat Mar 16 15:12:36 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.859697\tvalid_1's auc: 0.829702\n",
      "[600]\ttraining's auc: 0.893561\tvalid_1's auc: 0.859281\n",
      "[900]\ttraining's auc: 0.911197\tvalid_1's auc: 0.873906\n",
      "[1200]\ttraining's auc: 0.922512\tvalid_1's auc: 0.882418\n",
      "[1500]\ttraining's auc: 0.930494\tvalid_1's auc: 0.8875\n",
      "[1800]\ttraining's auc: 0.936884\tvalid_1's auc: 0.891694\n",
      "[2100]\ttraining's auc: 0.941963\tvalid_1's auc: 0.894331\n",
      "[2400]\ttraining's auc: 0.946288\tvalid_1's auc: 0.896424\n",
      "[2700]\ttraining's auc: 0.950038\tvalid_1's auc: 0.898031\n",
      "[3000]\ttraining's auc: 0.953437\tvalid_1's auc: 0.89902\n",
      "[3300]\ttraining's auc: 0.956588\tvalid_1's auc: 0.899613\n",
      "[3600]\ttraining's auc: 0.959602\tvalid_1's auc: 0.899972\n",
      "[3900]\ttraining's auc: 0.962409\tvalid_1's auc: 0.900397\n",
      "[4200]\ttraining's auc: 0.965124\tvalid_1's auc: 0.900445\n",
      "Early stopping, best iteration is:\n",
      "[4144]\ttraining's auc: 0.964614\tvalid_1's auc: 0.900515\n",
      "AUC = 0.900515163697768\n",
      "CPU times: user 1h 57min 55s, sys: 4.1 s, total: 1h 57min 59s\n",
      "Wall time: 29min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_preds_lgb = np.zeros((len(train), 1))\n",
    "y_pred_lgb = np.zeros(len(test))\n",
    "roc_cv_lgb =[]\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(train,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = train[original_features].iloc[train_index, :], train[original_features].iloc[valid_index, :]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(n_estimators=10000,**params_tuned)\n",
    "    lgb_model.fit(X_train,y_train,\n",
    "                    eval_set = [(X_train,y_train), (X_valid,y_valid)],verbose=300,early_stopping_rounds = 200)\n",
    "\n",
    "    val_pred = lgb_model.predict_proba(X_valid)[:,1]\n",
    "    print(\"AUC = {}\".format(roc_auc_score(y_valid, val_pred)))\n",
    "    oof_preds_lgb[valid_index] = val_pred.reshape((-1, 1))\n",
    "    \n",
    "    roc_cv_lgb.append(roc_auc_score(y_valid, val_pred))\n",
    "    \n",
    "    y_pred_lgb += lgb_model.predict_proba(test[original_features])[:,1]/NFOLDS #, num_iteration=lgb_model.best_iteration)/5\n",
    "y_pred_lgb = y_pred_lgb.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8997542441757086,\n",
      " 0.8996298314994977,\n",
      " 0.9018637772781452,\n",
      " 0.8975483339279146,\n",
      " 0.8971079289489183,\n",
      " 0.8959785840115708,\n",
      " 0.9002147682930539,\n",
      " 0.8979186059695962,\n",
      " 0.8941248262750917,\n",
      " 0.900515163697768]\n"
     ]
    }
   ],
   "source": [
    "pprint(roc_cv_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foldしないでテストデータ予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.39421465183790383, bagging_freq=5,\n",
       "        boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=0.7931590791796129,\n",
       "        feature_fraction=0.742029399864705, importance_type='split',\n",
       "        learning_rate=0.008467089868304085, max_depth=-1, max_leaves=962,\n",
       "        metric='auc', min_child_samples=20,\n",
       "        min_child_weight=0.016977338542881623, min_data_in_leaf=101,\n",
       "        min_gain_to_split=0.06117879704656666, min_split_gain=0.0,\n",
       "        n_estimators=5000, n_jobs=-1, num_leaves=31, num_threads=4,\n",
       "        objective='binary', random_state=823, reg_alpha=0.1659749229798302,\n",
       "        reg_lambda=1.4223979160695897, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0, verbosity=-1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(n_estimators=5000,**params_tuned)\n",
    "lgb_model.fit(train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb_single = lgb_model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foldでやったときとの差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1788.4834714081546"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(y_pred_lgb - y_pred_lgb_single).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自分の考えるスタッキング(うまく行ってない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 0\n",
      "0.5572748947620956\n",
      "AUC = 0.8950171466311798\n",
      "rev= 0.8974241341239989\n",
      "ave= 0.8989273784454206\n",
      "log= 0.897495248691385\n",
      "lgb= 0.8960491099022705\n",
      "max= 0.9340548734973438\n",
      "min= 0.8448987007742826\n",
      "Current Fold: 1\n",
      "0.5472144196245284\n",
      "AUC = 0.9026414519950692\n",
      "rev= 0.9044106294805135\n",
      "ave= 0.9058489231959866\n",
      "log= 0.9039580188086572\n",
      "lgb= 0.9043702353118201\n",
      "max= 0.9391073694424535\n",
      "min= 0.8565930795969816\n",
      "Current Fold: 2\n",
      "0.5601017788509441\n",
      "AUC = 0.8914782433279254\n",
      "rev= 0.8953573390675834\n",
      "ave= 0.8962100727082314\n",
      "log= 0.8924111319993476\n",
      "lgb= 0.895980230571794\n",
      "max= 0.9335953662451821\n",
      "min= 0.8380586172559723\n",
      "Current Fold: 3\n",
      "0.5583245178701275\n",
      "AUC = 0.894916060452756\n",
      "rev= 0.8986766219493049\n",
      "ave= 0.8995895771912379\n",
      "log= 0.8967359233350197\n",
      "lgb= 0.8980766300903069\n",
      "max= 0.9357177165651949\n",
      "min= 0.8418489378899685\n",
      "Current Fold: 4\n",
      "0.5518683835443744\n",
      "AUC = 0.8969727038213299\n",
      "rev= 0.9001740394361888\n",
      "ave= 0.9014584662254367\n",
      "log= 0.8992596292633755\n",
      "lgb= 0.8991212527239366\n",
      "max= 0.936406642523898\n",
      "min= 0.8459420236050126\n",
      "Current Fold: 5\n",
      "0.5551442732701729\n",
      "AUC = 0.8929485500090688\n",
      "rev= 0.8979485851065684\n",
      "ave= 0.8982139674915637\n",
      "log= 0.8948259265909753\n",
      "lgb= 0.8970655999442063\n",
      "max= 0.934811489064638\n",
      "min= 0.841044895589467\n",
      "Current Fold: 6\n",
      "0.5544522987560961\n",
      "AUC = 0.897223\n",
      "rev= 0.8995933333333334\n",
      "ave= 0.9011343333333333\n",
      "log= 0.8996445555555556\n",
      "lgb= 0.8985047777777777\n",
      "max= 0.9359132222222223\n",
      "min= 0.8480233333333332\n",
      "Current Fold: 7\n",
      "0.5558826908765659\n",
      "AUC = 0.901856012041794\n",
      "rev= 0.9056294906725437\n",
      "ave= 0.9068155359568059\n",
      "log= 0.903740976868568\n",
      "lgb= 0.9054933702243789\n",
      "max= 0.9409299075857785\n",
      "min= 0.8536459043486533\n",
      "Current Fold: 8\n",
      "0.5516369434295118\n",
      "AUC = 0.891442047535815\n",
      "rev= 0.8987878001320954\n",
      "ave= 0.8980500331461336\n",
      "log= 0.8933992319171744\n",
      "lgb= 0.8980344637493843\n",
      "max= 0.9349848682145094\n",
      "min= 0.8408935543698348\n",
      "Current Fold: 9\n",
      "0.5497114291724337\n",
      "AUC = 0.8955164580573339\n",
      "rev= 0.8989189637772672\n",
      "ave= 0.8997942070974901\n",
      "log= 0.8977270333013851\n",
      "lgb= 0.8982171136620946\n",
      "max= 0.9351688933665114\n",
      "min= 0.8456538181549242\n",
      "Current Fold: 10\n",
      "0.5603303053282638\n",
      "AUC = 0.87775049889169\n",
      "rev= 0.8826196388166201\n",
      "ave= 0.883314906259448\n",
      "log= 0.880183397825108\n",
      "lgb= 0.8817477197316661\n",
      "max= 0.9250228364023174\n",
      "min= 0.8200841219894175\n",
      "Current Fold: 11\n",
      "0.5535400083787181\n",
      "AUC = 0.8982133234828501\n",
      "rev= 0.9011569146112092\n",
      "ave= 0.9022799489297777\n",
      "log= 0.9001150873597678\n",
      "lgb= 0.9006728632720572\n",
      "max= 0.936891215210942\n",
      "min= 0.8489858854854911\n",
      "Current Fold: 12\n",
      "0.5633217197937492\n",
      "AUC = 0.8981573799292824\n",
      "rev= 0.9015404475828156\n",
      "ave= 0.902648804364873\n",
      "log= 0.9007025276833963\n",
      "lgb= 0.8999018607360835\n",
      "max= 0.9371199492925413\n",
      "min= 0.8497005210200055\n",
      "Current Fold: 13\n",
      "0.5501855161307999\n",
      "AUC = 0.9002907849745199\n",
      "rev= 0.9045877280283992\n",
      "ave= 0.9050039693787385\n",
      "log= 0.9025893586044137\n",
      "lgb= 0.9036174714954701\n",
      "max= 0.9383583220531461\n",
      "min= 0.8527375087311733\n",
      "Current Fold: 14\n",
      "0.5659380663830051\n",
      "AUC = 0.8968053264316267\n",
      "rev= 0.896687663748149\n",
      "ave= 0.8992398024759655\n",
      "log= 0.8986402935420529\n",
      "lgb= 0.8962460994052107\n",
      "max= 0.9352645599338805\n",
      "min= 0.8461516509545275\n",
      "Current Fold: 15\n",
      "0.5495484493259799\n",
      "AUC = 0.8967042844677737\n",
      "rev= 0.9007972624610393\n",
      "ave= 0.9017638857171659\n",
      "log= 0.8990822108381625\n",
      "lgb= 0.8994116033256703\n",
      "max= 0.9366728573295023\n",
      "min= 0.8458419946240493\n",
      "Current Fold: 16\n",
      "0.5590205123019362\n",
      "AUC = 0.8934024352505175\n",
      "rev= 0.8957331613048632\n",
      "ave= 0.8970797198770797\n",
      "log= 0.8944108134948148\n",
      "lgb= 0.8960881791173813\n",
      "max= 0.9337660676924107\n",
      "min= 0.8398659472108542\n",
      "Current Fold: 17\n",
      "0.5558794931431195\n",
      "AUC = 0.8921996659243486\n",
      "rev= 0.8931042640592342\n",
      "ave= 0.8950532559341443\n",
      "log= 0.8935518924110429\n",
      "lgb= 0.8929287320484304\n",
      "max= 0.9325870181477939\n",
      "min= 0.8385356415792754\n",
      "Current Fold: 18\n",
      "0.5481587933757011\n",
      "AUC = 0.9014874014874014\n",
      "rev= 0.9043008618766195\n",
      "ave= 0.905322287140469\n",
      "log= 0.9030649485194938\n",
      "lgb= 0.9041158616916192\n",
      "max= 0.938652705319372\n",
      "min= 0.8554308766429979\n",
      "Current Fold: 19\n",
      "0.5530185054100517\n",
      "AUC = 0.8966689716401955\n",
      "rev= 0.8994544656255089\n",
      "ave= 0.9004940770091296\n",
      "log= 0.8985534762848428\n",
      "lgb= 0.8986698756500942\n",
      "max= 0.9362402249884302\n",
      "min= 0.8452611218568665\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "target2 = np.argmin(np.vstack((np.abs(oof_preds.reshape(-1)-y),np.abs(oof_preds_lgb.reshape(-1)-y))),axis=0)\n",
    "oof_preds2 = np.zeros((len(train_logistic), 1))\n",
    "test_preds2 = np.zeros((len(test_logistic), 1))\n",
    "roc_cv2 =[]\n",
    "for fold_, (trn_, val_) in enumerate(folds.split(train_logistic, target2)):\n",
    "    print(\"Current Fold: {}\".format(fold_))\n",
    "    trn_x, trn_y = train_logistic.iloc[trn_, :], target2[trn_]\n",
    "    val_x, val_y, target_val, pred1_val, pred2_val = train_logistic.iloc[val_], target2[val_], y[val_], oof_preds[val_], oof_preds_lgb[val_]\n",
    "    target_val = target_val.reshape(-1)\n",
    "    pred1_val = pred1_val.reshape(-1)\n",
    "    pred2_val = pred2_val.reshape(-1)\n",
    "    \n",
    "    clf =  LogisticRegression(solver='lbfgs', max_iter=1500, C=10)\n",
    "\n",
    "    clf.fit(trn_x, trn_y)\n",
    "\n",
    "    val_pred = clf.predict(val_x).reshape(-1)\n",
    "    test_fold_pred = clf.predict_proba(test_logistic)[:,1].reshape(-1)\n",
    "    \n",
    "    val_pred_class = (1-val_pred)*pred1_val + val_pred*pred2_val\n",
    "    test_fold_pred_class = (1-test_fold_pred)*test_preds + test_fold_pred*y_pred_lgb\n",
    "    \n",
    "    fold_score = roc_auc_score(target_val, val_pred_class)\n",
    "    roc_cv2.append(fold_score)\n",
    "    \n",
    "    print(roc_auc_score(val_y,val_pred))\n",
    "    print(\"AUC = {}\".format(fold_score))\n",
    "    print(\"rev=\",roc_auc_score(target_val,(1-val_pred)*pred2_val + val_pred*pred1_val))\n",
    "    print(\"ave=\",roc_auc_score(target_val,(pred1_val+pred2_val)/2))\n",
    "    print(\"log=\",roc_auc_score(target_val,pred1_val))\n",
    "    print(\"lgb=\",roc_auc_score(target_val,pred2_val))\n",
    "    print(\"max=\",roc_auc_score(target_val,(1-val_y)*pred1_val + val_y*pred2_val))\n",
    "    print(\"min=\",roc_auc_score(target_val,(1-val_y)*pred2_val + val_y*pred1_val))\n",
    "    oof_preds2[val_] = val_pred_class.reshape((-1, 1))\n",
    "    test_preds2 += test_fold_pred_class.reshape((-1, 1))\n",
    "\n",
    "test_preds2/=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 確認用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev= 0.8979429999104619\n",
      "rev= 0.8991064541775937\n",
      "rev= 0.8985534762848428\n",
      "rev= 0.8986698756500942\n",
      "ave= 0.9004940770091296\n"
     ]
    }
   ],
   "source": [
    "a  = np.random.rand(val_pred.shape[0])\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred1_val + a*pred2_val))\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred2_val + a*pred1_val))\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred1_val + a*pred1_val))\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred2_val + a*pred2_val))\n",
    "print(\"ave=\",roc_auc_score(target_val,(pred1_val+pred2_val)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rev= 0.9004940770091296\n",
      "rev= 0.9004940770091296\n",
      "rev= 0.8985534762848428\n",
      "rev= 0.8986698756500942\n",
      "ave= 0.9004940770091296\n"
     ]
    }
   ],
   "source": [
    "a  = np.ones(val_pred.shape[0])/2\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred1_val + a*pred2_val))\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred2_val + a*pred1_val))\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred1_val + a*pred1_val))\n",
    "print(\"rev=\",roc_auc_score(target_val,(1-a)*pred2_val + a*pred2_val))\n",
    "print(\"ave=\",roc_auc_score(target_val,(pred1_val+pred2_val)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8975665283512196\n",
      "0.8982480202268966\n",
      "0.8956609102374608\n",
      "0.8999414605379313\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y,oof_preds))\n",
    "print(roc_auc_score(y,oof_preds_lgb))\n",
    "print(roc_auc_score(y,oof_preds2))\n",
    "print(roc_auc_score(y,(oof_preds+oof_preds_lgb)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f33577270febfac2d7c58b2fffef3eded8219629"
   },
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_uuid": "7ff36e1f3762c21af0ea048aea944a9e5e5b76d6"
   },
   "outputs": [],
   "source": [
    "submission_lgb = pd.DataFrame({\n",
    "        \"ID_code\": test_ids,\n",
    "        \"target\":\n",
    "    })\n",
    "submission_lgb.to_csv(savepath + 'csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f56b57e800c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_preds_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "target2 = np.argmin(np.vstack((np.abs(oof_preds.reshape(-1)-target),np.abs(oof_preds_lgb.reshape(-1)-target))),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightgbmのハイパーパラメーター調整 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_itr=0\n",
    "def objective_optuna(X, y, trial):\n",
    "    NFOLDS = 10\n",
    "    RANDOM_STATE = 823\n",
    "    folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "                        random_state=RANDOM_STATE)\n",
    "\n",
    "    global count_itr\n",
    "    print(count_itr, end=' ')\n",
    "    count_itr += 1\n",
    "    #最適化するパラメータを指定\n",
    "    params = {\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 5, 1000),\n",
    "        'min_data_in_leaf':  trial.suggest_int('min_data_in_leaf', 10, 1000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate',0,1),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction',0,1),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction',0.2,1),\n",
    "        'reg_alpha': trial.suggest_uniform('reg_alpha',0,5),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda',0,5),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree',0,1),\n",
    "        'min_gain_to_split': trial.suggest_loguniform('min_gain_to_split',1e-4,1),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight',1e-3,1000),\n",
    "        'boosting': 'gbdt',\n",
    "        'bagging_freq': 5, \n",
    "        'num_threads': 4,\n",
    "        'objective': 'binary',\n",
    "        'random_state': 823,\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "#         'tree_learner': 'data'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    oof_preds_lgb = np.zeros(len(X))\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "#         print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index, :], X.iloc[valid_index, :]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "\n",
    "        lgb_model = lgb.LGBMClassifier(n_estimators=5000,**params)\n",
    "        lgb_model.fit(X_train,y_train,\n",
    "                        eval_set = [(X_train,y_train), (X_valid,y_valid)],verbose=False,early_stopping_rounds = 200)\n",
    "\n",
    "        val_pred = lgb_model.predict_proba(X_valid)[:,1]\n",
    "#         print(\"AUC = {}\".format(roc_auc_score(y_valid, val_pred)))\n",
    "        oof_preds_lgb[valid_index] = val_pred.reshape(-1)\n",
    "      \n",
    "    return -roc_auc_score(y,oof_preds_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'objective_optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-eb7e272643b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective_optuna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'objective_optuna' is not defined"
     ]
    }
   ],
   "source": [
    "f = partial(objective_optuna, train, y)\n",
    "study = optuna.create_study()\n",
    "study.optimize(f, n_trials=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_dim=train.shape[1],name = \"lay1\"),\n",
    "    Activation('relu'),\n",
    "    Dense(1,name=\"lay2\"),\n",
    "    Activation('softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')#, metrics=['auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (200000, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-106a3f514a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習処理の実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;31m# using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 check_loss_and_target_compatibility(\n\u001b[0;32m--> 809\u001b[0;31m                     y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/kaggle_standard/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 raise ValueError(\n\u001b[1;32m    272\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (200000, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "# 学習処理の実行\n",
    "model.fit(train, y, batch_size=200, verbose=True, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - ETA: 58 - ETA: 7 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 7s 35us/step\n"
     ]
    }
   ],
   "source": [
    "scr = model.evaluate(train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.340334671020507"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, input_shape=(train.shape[1],)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.2293 - acc: 0.9160 - val_loss: 0.2337 - val_acc: 0.9137\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.2298 - acc: 0.9159 - val_loss: 0.2337 - val_acc: 0.9137\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.2292 - acc: 0.9161 - val_loss: 0.2337 - val_acc: 0.9137\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.2296 - acc: 0.9162 - val_loss: 0.2337 - val_acc: 0.9136\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.2296 - acc: 0.9159 - val_loss: 0.2337 - val_acc: 0.9136\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.2294 - acc: 0.9162 - val_loss: 0.2337 - val_acc: 0.9136\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, keras.utils.np_utils.to_categorical(y),\n",
    "                 batch_size=50000,\n",
    "                 verbose=2,\n",
    "                 epochs=100,\n",
    "                 validation_split=0.1,\n",
    "                 callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = model.predict_proba(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8643111086556021"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y,pre[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_standard",
   "language": "python",
   "name": "kaggle_standard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
