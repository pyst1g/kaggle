{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://www.kaggle.com/ruby33421/lgbm-with-new-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93d7b4b8f5f6e5289cfc0312d650744e64905bc7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Intro\n",
    "Please see Alexey Pronin's kernel (https://www.kaggle.com/graf10a/logistic-regression-with-new-features-feather) to read more on feature engineering and the performance benefit of using feather files.\n",
    "Alexey Pronin's kernel also references Youri Matiounine's work here: (https://www.kaggle.com/ymatioun/santander-linear-model-with-additional-features) \n",
    "\n",
    "The featuring engineering process adds 1000 new features, which means a total of 1200 features for the Santander dataset. The original kernel uses a simple logistic regression for training, which achieves a very good score of 0.896 (AUC). This kernel will use Light GBM model, but instead of using incorporating all the 1K additional features in our model, we will use feature importance to select some of the top engineered features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "319c9748ad2d9b82cc875000f58afa2129aeb9c3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import shutil\n",
    "import sklearn\n",
    "import feather\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from functools import partial\n",
    "from scipy.stats import norm, rankdata\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from numpy import sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31a0c430046df842333652c410b3181d800f0551"
   },
   "source": [
    "Now, let's read the CSV files containing the training and testing data and measure how long it takes.\n",
    "\n",
    "Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "0d080b4a0bf27808a316196c71948a96280ef177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data...\n",
      "It takes 4.77 seconds to read 'train.csv'.\n"
     ]
    }
   ],
   "source": [
    "path_train = '../input/train.feather'\n",
    "path_test = '../input/test.feather'\n",
    "\n",
    "print(\"Reading train data...\")\n",
    "start = time.time()\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"It takes {0:.2f} seconds to read 'train.csv'.\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e6904f34859901e764adde45ed0bb3bc13e4f58"
   },
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0fca1a0b7f595147cc5c3641b1a45c9d7f8e2340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data...\n",
      "It takes 4.62 seconds to read 'test.csv'.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Reading test data...\")\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"It takes {0:.2f} seconds to read 'test.csv'.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "733bef277c96bbdec20afcbd9c2009865ea863f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (200000, 202)\n",
      "Test:  (200000, 201)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \",train.shape)\n",
    "print(\"Test: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c74d587203855a0a8eb7da6b2f6abb3090bb60d"
   },
   "source": [
    "Saving the 'target' and 'ID_code' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "74a87959eb66d371c314180f4877d1afdde136b7"
   },
   "outputs": [],
   "source": [
    "target = train.pop('target')\n",
    "train_ids = train.pop('ID_code')\n",
    "test_ids = test.pop('ID_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c2c537288b4915a1f860065a2046e47cae19459"
   },
   "source": [
    "Saving the number of rows in 'train' for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b1026519541d70d9206f9941fc29d19005fa1dcd"
   },
   "outputs": [],
   "source": [
    "len_train = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af2947142503c41f3c26e9c805e14e033fceb955"
   },
   "source": [
    "Merging test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "fc7bb057b85c4a8b12b102e7432e261ff6a92954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.concat([train, test])\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b29b8bd47b43d76ee650e12e063c34c3c1ad189"
   },
   "source": [
    "Removing data we no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "bca8a00d9d62f3a4479c524b66d6e906ac155b7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test, train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef8301089d9bfd8880ad0165e3d1c248a5fb1fde"
   },
   "source": [
    "Saving the list of original features in a new list `original_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "134f8d281a4fafdbbbd51fb3429015d271d895ac"
   },
   "outputs": [],
   "source": [
    "original_features = merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c759bfea1d90b899118ed5a153a0189ea10d7a6c"
   },
   "source": [
    "## Computing new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "06df646dee338e944955dd6059df57cd6c73afa0"
   },
   "outputs": [],
   "source": [
    "for col in merged.columns:\n",
    "    # Normalize the data, so that it can be used in norm.cdf(), \n",
    "    # as though it is a standard normal variable\n",
    "    merged[col] = ((merged[col] - merged[col].mean()) \n",
    "    / merged[col].std()).astype('float32')\n",
    "\n",
    "    # Square\n",
    "    merged[col+'^2'] = merged[col] * merged[col]\n",
    "\n",
    "    # Cube\n",
    "    merged[col+'^3'] = merged[col] * merged[col] * merged[col]\n",
    "\n",
    "    # 4th power\n",
    "    merged[col+'^4'] = merged[col] * merged[col] * merged[col] * merged[col]\n",
    "\n",
    "    # Cumulative percentile (not normalized)\n",
    "    merged[col+'_cp'] = rankdata(merged[col]).astype('float32')\n",
    "\n",
    "    # Cumulative normal percentile\n",
    "    merged[col+'_cnp'] = norm.cdf(merged[col]).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5fd487e4440606deb9e936346e982513f0718c9"
   },
   "source": [
    "Getting the list of names of the added features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "456a64b4d2c1ada1b6db546a1d004537df4bd238"
   },
   "outputs": [],
   "source": [
    "new_features = set(merged.columns) - set(original_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8188eb856e421905972cc6f34ab4b43e87dd41f8"
   },
   "source": [
    "Normalize the data. Again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "7180731459fe9ce60f95b94b77f3d7f9a565823d"
   },
   "outputs": [],
   "source": [
    "for col in new_features:\n",
    "    merged[col] = ((merged[col] - merged[col].mean()) \n",
    "    / merged[col].std()).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f1039a0b002c1db092a9b3d590759531facc3e6"
   },
   "source": [
    "Saving the data to feather files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "9f04f23ad704daa0207a03c9c6e5d680ac0caed8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing target to a feather files...\n",
      "Writing train_ids to a feather files...\n",
      "Writing test_ids to a feather files...\n",
      "Writing train to a feather files...\n",
      "Writing test to a feather files...\n"
     ]
    }
   ],
   "source": [
    "path_target = 'target.feather'\n",
    "\n",
    "path_train_ids = 'train_ids_extra_features.feather'\n",
    "path_test_ids = 'test_ids_extra_features.feather'\n",
    "\n",
    "path_train = 'train_extra_features.feather'\n",
    "path_test = 'test_extra_features.feather'\n",
    "\n",
    "print(\"Writing target to a feather files...\")\n",
    "pd.DataFrame({'target' : target.values}).to_feather(path_target)\n",
    "\n",
    "print(\"Writing train_ids to a feather files...\")\n",
    "pd.DataFrame({'ID_code' : train_ids.values}).to_feather(path_train_ids)\n",
    "\n",
    "print(\"Writing test_ids to a feather files...\")\n",
    "pd.DataFrame({'ID_code' : test_ids.values}).to_feather(path_test_ids)\n",
    "\n",
    "print(\"Writing train to a feather files...\")\n",
    "feather.write_dataframe(merged.iloc[:len_train], path_train)\n",
    "\n",
    "print(\"Writing test to a feather files...\")\n",
    "feather.write_dataframe(merged.iloc[len_train:], path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "640948a1a36e2d3d73f18ceb9cfb816be6d11d7b"
   },
   "source": [
    "Removing data we no longer need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del target, train_ids, test_ids, merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "837f988316528d5c3d4530043448fe5849be3fa5"
   },
   "source": [
    "## Loading the data from feather files\n",
    "\n",
    "Now let's load of these data back into memory. This will help us to illustrate the advantage of using the feather file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "60b26db1cf85167b14f9223af995a8656bdaa316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sano/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning:\n",
      "\n",
      ".labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012558 sec\n"
     ]
    }
   ],
   "source": [
    "path_target = 'target.feather'\n",
    "\n",
    "path_train_ids = 'train_ids_extra_features.feather'\n",
    "path_test_ids = 'test_ids_extra_features.feather'\n",
    "\n",
    "path_train = 'train_extra_features.feather'\n",
    "path_test = 'test_extra_features.feather'\n",
    "\n",
    "print(\"Reading target\")\n",
    "start = time.time()\n",
    "y = feather.read_dataframe(path_target).values.ravel()\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2f60516cb907e9e62f97eb99ebb00db079edc6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train_ids\n",
      "0.010859 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading train_ids\")\n",
    "start = time.time()\n",
    "train_ids = feather.read_dataframe(path_train_ids).values.ravel()\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4c8ad8191f0a4cd976645e7d7b59f7c16c48311f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test_ids\n",
      "0.024150 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading test_ids\")\n",
    "start = time.time()\n",
    "test_ids = feather.read_dataframe(path_test_ids).values.ravel()\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "afe5ba0c48d46a05e09c2de00b094a5a479fded6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data\n",
      "0.277851 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading training data\")\n",
    "\n",
    "start = time.time()\n",
    "train = feather.read_dataframe(path_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4764997b330eb79e2962c6ea207b2bf43d75b7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading testing data\n",
      "0.259630 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading testing data\")\n",
    "\n",
    "start = time.time()\n",
    "test = feather.read_dataframe(path_test)\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0:5f} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8c278ce260046cb0adfa633f557cf97fa63f2e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  1200\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of features: \",train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3d1c00f01bdcc40525a6d59cf3bc463bdbcef11"
   },
   "source": [
    "Hopefully now you can see the great advantage of using the feather files: it is blazing fast. Just compare the timings shown above with those measured for the original CSV files: the processed data sets (stored in the feather file format) that we have just loaded are much bigger in size that the original ones (stored in the CSV files) but we can load them in almost no time!\n",
    "\n",
    "# Logistic regession with the added features.\n",
    "\n",
    "Now let's finally do some modeling! More specifically, we will build a straighforward logistic regression model to see whether or not we can improve on linear regression result (LB 0.894). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "72ddd6eee811099caba7f2cc610e7f099d8fa84f"
   },
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "RANDOM_STATE = 871972\n",
    "\n",
    "feature_list = train.columns\n",
    "\n",
    "test = test[feature_list]\n",
    "\n",
    "X = train.values.astype(float)\n",
    "X_test = test.values.astype(float)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, \n",
    "                        random_state=RANDOM_STATE)\n",
    "oof_preds = np.zeros((len(train), 1))\n",
    "test_preds = np.zeros((len(test), 1))\n",
    "roc_cv =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Fold: 0\n",
      "AUC = 0.8976432005780828\n",
      "Current Fold: 1\n",
      "AUC = 0.8969755043464758\n",
      "Current Fold: 2\n",
      "AUC = 0.8996586412019945\n",
      "Current Fold: 3\n",
      "AUC = 0.8962648030526484\n",
      "Current Fold: 4\n",
      "AUC = 0.8950120474162403\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n",
    "    print(\"Current Fold: {}\".format(fold_))\n",
    "    trn_x, trn_y = X[trn_, :], y[trn_]\n",
    "    val_x, val_y = X[val_, :], y[val_]\n",
    "    \n",
    "    clf =  LogisticRegression(solver='lbfgs', max_iter=1500, C=10)\n",
    "\n",
    "    clf.fit(trn_x, trn_y)\n",
    "\n",
    "    val_pred = clf.predict_proba(val_x)[:,1]\n",
    "    test_fold_pred = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    roc_cv.append(roc_auc_score(val_y, val_pred))\n",
    "    \n",
    "    print(\"AUC = {}\".format(roc_auc_score(val_y, val_pred)))\n",
    "    oof_preds[val_, :] = val_pred.reshape((-1, 1))\n",
    "    test_preds += test_fold_pred.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_logistic = pd.DataFrame({\n",
    "        \"ID_code\": test_ids,\n",
    "        \"target\": test_preds.reshape(-1)\n",
    "})\n",
    "submission_logistic.to_csv('submission_logistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de1e4b00f84f8299f1eeff9f09e63e6299add289"
   },
   "source": [
    "### Feature Importance & Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6df10f59e9448863064fddd4312961ddbe243f20"
   },
   "outputs": [],
   "source": [
    "feature_importance = abs(clf.coef_[0])\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bca957e6843f437ec776670c613e0da3280f28ed"
   },
   "outputs": [],
   "source": [
    "top_new_features = feature_list[sorted_idx[0:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec76bf256250c72a45ad81a6c28134e47088ed2f"
   },
   "outputs": [],
   "source": [
    "train_newf = train[top_new_features]\n",
    "Orig_feature_list = list(original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "229583d56728e9a1a98ce539f4ff9bcc6b549f72"
   },
   "outputs": [],
   "source": [
    "cols = [col for col in train_newf.columns if col not in Orig_feature_list]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_newf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "132fd0efaf0adf943b038720f8f1062c319aafd3"
   },
   "outputs": [],
   "source": [
    "train2 = pd.concat([train[original_features], train[cols]], axis=1)\n",
    "test2 = test[train2.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb198e54be7b7da392a35c0db059741e0db49149"
   },
   "source": [
    "## LGBM model with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b234e4461ee4c2102f58a6cd5c47fe09282b9981"
   },
   "outputs": [],
   "source": [
    "fold_n=5\n",
    "folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddfa502a30e24b3dd5f3241f9719848583e5312f"
   },
   "outputs": [],
   "source": [
    "X = train2.values.astype(float)\n",
    "X_test = test2.values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "d176ad7c3da9dc712e3abf6f57ce7271ea7e7a94"
   },
   "outputs": [],
   "source": [
    "params_tuned = {'num_leaves': 9,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 11,\n",
    "         'learning_rate': 0.03,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 3,\n",
    "         'reg_lambda': 5,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'colsample_bytree': 0.7,\n",
    "#         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.02,\n",
    "#         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "6242795eb4018c0a9defa877e56515a2464fe8ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Fri Mar  8 23:12:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.876081\tvalid_1's auc: 0.85122\n",
      "[600]\ttraining's auc: 0.903321\tvalid_1's auc: 0.874298\n",
      "[900]\ttraining's auc: 0.916552\tvalid_1's auc: 0.884868\n",
      "[1200]\ttraining's auc: 0.924382\tvalid_1's auc: 0.890067\n",
      "[1500]\ttraining's auc: 0.930065\tvalid_1's auc: 0.893369\n",
      "[1800]\ttraining's auc: 0.934512\tvalid_1's auc: 0.895567\n",
      "[2100]\ttraining's auc: 0.938381\tvalid_1's auc: 0.896681\n",
      "[2400]\ttraining's auc: 0.942003\tvalid_1's auc: 0.897196\n",
      "[2700]\ttraining's auc: 0.945713\tvalid_1's auc: 0.897343\n",
      "[3000]\ttraining's auc: 0.949116\tvalid_1's auc: 0.897518\n",
      "Early stopping, best iteration is:\n",
      "[2850]\ttraining's auc: 0.947458\tvalid_1's auc: 0.897579\n",
      "Fold 1 started at Fri Mar  8 23:18:40 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.875468\tvalid_1's auc: 0.851887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    211\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1753\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_lgb = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X[train_index, :], X[valid_index, :]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    lgb_model = lgb.train(params_tuned,train_data,num_boost_round=5000,\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 200)\n",
    "            \n",
    "    y_pred_lgb += lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_itr=0\n",
    "def objective_optuna(X, y, trial):\n",
    "    global count_itr\n",
    "    print(count_itr, end=' ')\n",
    "    count_itr += 1\n",
    "    #最適化するパラメータを指定\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',1,1000),\n",
    "        'gamma': trial.suggest_uniform('gamma',0,1),\n",
    "        'reg_lambda': trial.suggest_uniform('lambda',0,2),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate',0,0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "        'subsample': trial.suggest_uniform('subsample',0,1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree',0,1),\n",
    "        'min_child_weight': trial.suggest_uniform('min_child_weight',0,10),\n",
    "        'tree_method':'gpu_exact'\n",
    "    }\n",
    "    \n",
    "    #モデルを定義\n",
    "    model = xgb.XGBClassifier(random_state=2,**params)\n",
    "    \n",
    "#     (train_X, test_X ,train_y, test_y) = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "    \n",
    "#     #3-foldクロスバリデーション\n",
    "    kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=2)\n",
    "    scores = cross_validate(model, X=X, y=y, cv=kf, scoring='roc_auc')\n",
    "    \n",
    "    return 1.0 - scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-03-08 23:43:30,762] Finished a trial resulted in value: 0.165576625934182. Current best value is 0.165576625934182 with parameters: {'n_estimators': 511, 'gamma': 0.35291487336113525, 'lambda': 1.3895516004349984, 'learning_rate': 0.17423041322586422, 'max_depth': 9, 'subsample': 0.7319257294591153, 'colsample_bytree': 0.8784437620977481, 'min_child_weight': 8.273633209020229}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-03-09 00:13:00,276] Finished a trial resulted in value: 0.13351448604231597. Current best value is 0.13351448604231597 with parameters: {'n_estimators': 490, 'gamma': 0.9733822084942044, 'lambda': 1.2337653708464957, 'learning_rate': 0.06200839595128288, 'max_depth': 13, 'subsample': 0.39659485727811083, 'colsample_bytree': 0.49382731218251896, 'min_child_weight': 5.543425079888281}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-03-09 00:16:39,824] Finished a trial resulted in value: 0.1177019991863214. Current best value is 0.1177019991863214 with parameters: {'n_estimators': 387, 'gamma': 0.9577287900840181, 'lambda': 1.8829687459578166, 'learning_rate': 0.1211109191110216, 'max_depth': 3, 'subsample': 0.04628499940930242, 'colsample_bytree': 0.5230606855073078, 'min_child_weight': 2.1473782298925217}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-03-09 00:18:27,731] Finished a trial resulted in value: 0.2494588885852348. Current best value is 0.1177019991863214 with parameters: {'n_estimators': 387, 'gamma': 0.9577287900840181, 'lambda': 1.8829687459578166, 'learning_rate': 0.1211109191110216, 'max_depth': 3, 'subsample': 0.04628499940930242, 'colsample_bytree': 0.5230606855073078, 'min_child_weight': 2.1473782298925217}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-03-09 00:53:36,473] Finished a trial resulted in value: 0.16236016581527812. Current best value is 0.1177019991863214 with parameters: {'n_estimators': 387, 'gamma': 0.9577287900840181, 'lambda': 1.8829687459578166, 'learning_rate': 0.1211109191110216, 'max_depth': 3, 'subsample': 0.04628499940930242, 'colsample_bytree': 0.5230606855073078, 'min_child_weight': 2.1473782298925217}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 "
     ]
    }
   ],
   "source": [
    "f = partial(objective_optuna, X, y)\n",
    "study = optuna.create_study()\n",
    "study.optimize(f, n_trials=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f33577270febfac2d7c58b2fffef3eded8219629"
   },
   "source": [
    "## Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ff36e1f3762c21af0ea048aea944a9e5e5b76d6"
   },
   "outputs": [],
   "source": [
    "submission_lgb = pd.DataFrame({\n",
    "        \"ID_code\": test_ids,\n",
    "        \"target\": y_pred_lgb\n",
    "    })\n",
    "submission_lgb.to_csv('submission_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3b88b41d876338362d22fbeb552bf3ec6db964b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
