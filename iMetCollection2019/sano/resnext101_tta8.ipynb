{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import models\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "ON_KAGGLE: bool = 'KAGGLE_WORKING_DIR' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('save_name')\n",
    "arg('model', choices=['resnet34','resnet50', 'resnet101', 'resnet152', 'vgg16_bn', 'resnext101'])\n",
    "arg('cuda')\n",
    "arg('mode', choices=['train', 'test'])\n",
    "arg('valid_fold', type=int, choices=[0,1,2,3,4])\n",
    "arg('image_size', type=int)\n",
    "arg('--loss', choices=['BCE', 'FL'], default='BCE')\n",
    "arg('--pos_weight', type=int, default=1)\n",
    "arg('--use_tuned_pos_weight', action='store_true')\n",
    "arg('--no_pretrained', action='store_true')\n",
    "arg('--batch-size', type=int, default=50)\n",
    "arg('--epochs', type=int, default=50)\n",
    "arg('--tta', type=int, default=1)\n",
    "arg('--n_workers', type=int, default=3)\n",
    "arg('--lr', type=float, default=0.0001)\n",
    "arg('--verbose', action='store_true')\n",
    "arg('--lr_tuned', action='store_true')\n",
    "arg('--lr_dec_rate', type=int, default=2)\n",
    "args = parser.parse_args(args=['b','resnext101','cuda','test','0','328','--use_tuned_pos_weight','--batch-size', '10','--tta','8','--n_workers','5','--no_pretrained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_list is trained weight data with iMets train images <br>\n",
    "these files are created with <br>\n",
    "・resnext101_tta8.py ResNext101_lrt_p2t10BCE328_rrcflrono_f0 resnext101 cuda train 0 328 --pos_weight 2  --lr 0.00006666 --tta 10 --lr_tuned<br>\n",
    "・resnext101_tta8.py ResNext101_lrt_p2t4BCE328_rrcflno_f1 resnext101 cuda train 1 328 --pos_weight 2  --lr 0.00006666 --tta 4 --lr_tuned<br>\n",
    "・resnext101_tta8.py ResNext101_lrt_p2t4BCE328_rrcflno_f2 resnext101 cuda train 2 328 --pos_weight 2  --lr 0.00006666 --tta 4 --lr_tuned<br>\n",
    "・resnext101_tta8.py ResNext101_lrt_p2t4BCE328_rrcflno_f3 resnext101 cuda train 3 328 --pos_weight 2  --lr 0.00006666 --tta 4 --lr_tuned<br>\n",
    "・resnext101_tta8.py ResNext101_lrt_p2t10BCE328_rrcflno_f4 resnext101 cuda train 4 328 --pos_weight 2  --lr 0.00006666 --tta 10 --lr_tuned<br>\n",
    "\n",
    "respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = ['ResNext101_lrt_p2t10BCE328_rrcflrono_f0_epoch26.pkl', 'ResNext101_lrt_p2t4BCE328_rrcflno_f1_epoch16.pkl',\n",
    "               'ResNext101_lrt_p2t4BCE328_rrcflno_f2_epoch21.pkl', 'ResNext101_lrt_p2t4BCE328_rrcflno_f3_epoch17.pkl',\n",
    "               'ResNext101_lrt_p2t10BCE328_rrcflno_f4_epoch17.pkl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file, GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "log_dir =  runs/b\n",
      "weight save path =  ./model_weight/b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f29a3387f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path = \"../input/imet-2019-fgvc6/\" if ON_KAGGLE else \"/home/sano/Datasets/iMet_Colelction_2019/input/\"\n",
    "\n",
    "log_dir = 'runs/' + args.save_name\n",
    "weight_path = './model_weight/' + args.save_name\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "print('log_dir = ', log_dir)\n",
    "print('weight save path = ', weight_path)\n",
    "\n",
    "torch.manual_seed(823)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define resnext101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def _resnet(arch, inplanes, planes, pretrained, progress, **kwargs):\n",
    "    model = ResNet(inplanes, planes, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def resnext101_32x8d(pretrained,**kwargs):\n",
    "    kwargs['groups'] = 32\n",
    "    kwargs['width_per_group'] = 8\n",
    "    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
    "                   pretrained=pretrained, progress=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "num_classes = 1103\n",
    "extract_attribute = 5 # 予測した上位何個を属性として出力するか\n",
    "\n",
    "models_dict = {'resnet34'  : models.resnet34,\n",
    "               'resnet50'  : models.resnet50,\n",
    "               'resnet101' : models.resnet101,\n",
    "               'resnet152' : models.resnet152,\n",
    "               'vgg16_bn'  : models.vgg16_bn,\n",
    "               'resnext101': resnext101_32x8d\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.pos_weight * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iMetsDataset(data.Dataset):\n",
    " \n",
    "    def __init__(self, df, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (dataframe): ファイル名がindex、Nhot_LabelsカラムにNhot化したラベルを格納したDataframe\n",
    "            root_dir (string): 対象の画像ファイルが入っているフォルダ\n",
    "            transform (callable, optional): 施す変換\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "#         if type(idx) == torch.Tensor:\n",
    "#             idx = idx.item()\n",
    "        img_name = os.path.join(self.root_dir, self.df.index[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.mode == 'train':\n",
    "            label = self.df.iloc[idx].Nhot_Labels.astype('float32')\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "def Nhot_encoding(arr, l):\n",
    "    \"\"\"\n",
    "    Nhotエンコーディングを行う\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        ラベル\n",
    "    l : int\n",
    "        総ラベル数\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        ret = np.zeros(l,dtype='int')\n",
    "        ret[arr] = 1\n",
    "        return ret\n",
    "    else:\n",
    "        lst = list()\n",
    "        for i,_ in enumerate(arr):\n",
    "            lst.extend([i] * arr.shape[1])\n",
    "            \n",
    "        ret = np.zeros((arr.shape[0],l),dtype='int')\n",
    "        ret[lst,arr.flatten()] = 1\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = pd.read_csv(load_path + 'labels.csv')\n",
    "label_name = label_name.set_index(\"attribute_id\")\n",
    "submit_df = pd.read_csv(load_path + 'sample_submission.csv')\n",
    "submit_df[\"id\"] = submit_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "submit_df = submit_df.set_index('id')\n",
    "test_size = len(submit_df)\n",
    "\n",
    "train_df = pd.read_csv(load_path + 'train.csv')\n",
    "train_size = len(train_df)\n",
    "train_df[\"attribute_ids\"] = train_df[\"attribute_ids\"].apply(lambda x: np.array([int(s) for s in x.split(\" \")]))\n",
    "train_df[\"Nhot_Labels\"] = train_df[\"attribute_ids\"].apply(lambda x: Nhot_encoding(x,1103))\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "\n",
    "np.random.seed(823)\n",
    "fold = pd.Series(np.arange(len(train_df)) % 5)\n",
    "np.random.shuffle(fold)\n",
    "train_df['fold'] = fold\n",
    "del fold\n",
    "\n",
    "\n",
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "ds_allTrain = iMetsDataset(train_df,load_path+'train',mode ='train')\n",
    "\n",
    "\n",
    "# ds_train, ds_valid = data.random_split(ds_allTrain, [90000, 19237])\n",
    "ds_train = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] != args.valid_fold)[0]) \n",
    "ds_valid = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] == args.valid_fold)[0]) \n",
    "ds_train.dataset = deepcopy(ds_allTrain)\n",
    "\n",
    "\n",
    "ds_test = iMetsDataset(submit_df,load_path+'test', mode='test')\n",
    "\n",
    "\n",
    "\n",
    "ds_train.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size*2,args.image_size*2)),\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "\n",
    "if args.tta == 1:\n",
    "    ds_valid.dataset.transform = transforms.Compose([\n",
    "                                    transforms.Resize((args.image_size, args.image_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(\n",
    "                                        [0.485, 0.456, 0.406], \n",
    "                                        [0.229, 0.224, 0.225]\n",
    "                                    )\n",
    "                                ])\n",
    "else:\n",
    "    ds_valid.dataset.transform = ds_train.dataset.transform\n",
    "\n",
    "\n",
    "ds_test.transform = ds_valid.dataset.transform\n",
    "#                           transforms.Compose([\n",
    "#                                 transforms.Resize((args.image_size, args.image_size)),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(\n",
    "#                                     [0.485, 0.456, 0.406], \n",
    "#                                     [0.229, 0.224, 0.225]\n",
    "#                                 ),\n",
    "#                             ])\n",
    "\n",
    "\n",
    "if type(ds_train.indices) == torch.Tensor:\n",
    "    ds_train.indices = ds_train.indices.numpy()\n",
    "    ds_valid.indices = ds_valid.indices.numpy()\n",
    "\n",
    "\n",
    "dataloader_train = data.DataLoader(dataset=ds_train,batch_size=batch_size,shuffle=True,num_workers=args.n_workers)\n",
    "dataloader_valid = data.DataLoader(dataset=ds_valid,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)\n",
    "dataloader_test = data.DataLoader(dataset=ds_test,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate frequency of attributes and bias_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_attribute = Counter()\n",
    "for i in train_df.attribute_ids:\n",
    "    cnt_attribute.update(i)\n",
    "\n",
    "freq_attr = np.asarray(cnt_attribute.most_common())\n",
    "\n",
    "bias_pos_weight = np.zeros(num_classes)\n",
    "bias_pos_weight[freq_attr[:,0]] = (len(dataloader_train.dataset) / 2) / freq_attr[:,1]\n",
    "bias_pos_weight[bias_pos_weight>100] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "model = models_dict[args.model](pretrained = not args.no_pretrained)\n",
    "\n",
    "if args.model.startswith('resne'):\n",
    "    num_features = model.fc.in_features\n",
    "    features = list(model.fc.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.fc = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "elif args.model.startswith('vgg'):\n",
    "    num_features = model.classifier[-1].in_features\n",
    "    features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "# model.load_state_dict(torch.load('../input/imets-resnext101-fold5-tta8/ResNext101_lrt_p2t10BCE328_rrcflrono_f0_epoch26.pkl',map_location=device))\n",
    "# model.load_state_dict(torch.load('model_weight/'+weight_list[4],map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == 'BCE':\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "elif args.loss == 'FL':\n",
    "    criterion = FocalLoss(gamma=2, logits=True, pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "\n",
    "if args.use_tuned_pos_weight:\n",
    "    criterion.pos_weight = torch.from_numpy(bias_pos_weight)\n",
    "\n",
    "criterion.pos_weight = criterion.pos_weight.float().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25, 30, 35, 40, 45], gamma=1/args.lr_dec_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train,eval,predictの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "def train(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    steps = len(ds_train)//batch_size\n",
    "    for step, (images, labels) in enumerate(dataloader_train, 1):\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % (len(dataloader_train.dataset) // (60 * args.batch_size)) == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.10f, time: %d分%d秒' % (epoch, args.epochs, step, steps, loss.item(), elapsed_time//60, int(elapsed_time % 60)))\n",
    "            writer.add_scalar('train/train_loss', loss.item() , global_step)\n",
    "            \n",
    "def eval(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    # TTA topN\n",
    "    propotion_arr, labels_arr = pred_prop()\n",
    "#     pred_labels_topN = Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-extract_attribute:], num_classes)\n",
    "#     f2 = fbeta_score(labels_arr, pred_labels_topN, beta=2 ,average='samples')\n",
    "#     precision = precision_score(labels_arr,pred_labels_topN,average='samples')\n",
    "#     recall = recall_score(labels_arr,pred_labels_topN,average='samples')\n",
    "#     print(\"Val Acc(topN)   : %.10f\" % f2)\n",
    "#     print(\"precision(topN) : %.10f\" % precision)\n",
    "#     print(\"recall(topN)    : %.10f\" % recall)\n",
    "\n",
    "    \n",
    "    thr, max_f2 = make_only_threthold(np.mean(propotion_arr,axis=0),labels_arr)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\"elapsed_time: %d分%d秒\" % (elapsed_time//60, int(elapsed_time % 60)))\n",
    "    \n",
    "    pred_top12 = np.mean(propotion_arr,axis=0) * Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-12:], num_classes)\n",
    "#     pred_labels = np.mean(propotion_arr,axis=0) > thr\n",
    "    pred_labels = pred_top12 > thr\n",
    "    f2 = fbeta_score(labels_arr,pred_labels, beta=2 ,average='samples')\n",
    "    precision = precision_score(labels_arr,pred_labels,average='samples')\n",
    "    recall = recall_score(labels_arr,pred_labels,average='samples')\n",
    "    print(\"Val Acc   : %.10f\" % f2)\n",
    "    print(\"precision : %.10f\" % precision)\n",
    "    print(\"recall    : %.10f\" % recall)\n",
    "        \n",
    "#     writer.add_scalar('eval/val_acc', f2*100, epoch)\n",
    "#     writer.add_scalar('eval/precision', precision*100, epoch)\n",
    "#     writer.add_scalar('eval/recall', recall*100, epoch)\n",
    "    \n",
    "    return thr\n",
    "\n",
    "def predict(thr, dataloader=dataloader_test):\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    global model\n",
    "    for i in range(5):\n",
    "        model.load_state_dict(torch.load('../input/imets-resnext101-fold5-tta8/'+weight_list[i],map_location=device))\n",
    "        model = model.to(device)\n",
    "        propotion_arr_TTA += pred_test()\n",
    "        \n",
    "    propotion_arr_TTA /= 5\n",
    "    \n",
    "    \n",
    "\n",
    "    pred_top12 = propotion_arr_TTA * Nhot_encoding(np.argsort(propotion_arr_TTA, axis=1)[:,-12:], num_classes)\n",
    "#     pred_labels = propotion_arr_TTA > thr\n",
    "    pred_labels = pred_top12 > thr\n",
    "    \n",
    "    pos, label = np.where(pred_labels==1)\n",
    "    \n",
    "    pred_attr = list()\n",
    "    for i in range(len(dataloader_test.dataset)):\n",
    "        pred_attr.append(label[pos==i])\n",
    "    return pred_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_prop(dataloader = dataloader_valid):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    \n",
    "    for t in range(args.tta):\n",
    "        if t==0:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        if t==1:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        else:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "            \n",
    "        print(dataloader.dataset.dataset.transform)\n",
    "    \n",
    "        print(t, end=' ')\n",
    "        propotion_arr = list()\n",
    "        labels_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "                labels_arr.extend(labels)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "                if i % 10 == 0:\n",
    "                    elapsed_time = time.time() - start\n",
    "                    print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "                    clear_output(wait=True)\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        labels_arr = np.asarray(labels_arr)\n",
    "        propotion_arr_TTA += propotion_arr\n",
    "        elapsed_time = time.time() - start\n",
    "        print('time: %d分%d秒' % (elapsed_time//60, int(elapsed_time % 60)))\n",
    "    print()\n",
    "    propotion_arr_TTA /= args.tta\n",
    "    \n",
    "    return propotion_arr_TTA, labels_arr\n",
    "\n",
    "\n",
    "def pred_test(dataloader=dataloader_test):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    for t in range(args.tta):\n",
    "        if t==0:\n",
    "            ds_test.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        if t==1:\n",
    "            ds_test.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        else:\n",
    "            ds_test.transform = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        print(t, end=' ')\n",
    "        propotion_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, images in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "#                 if i % 10 == 0:\n",
    "#                     elapsed_time = time.time() - start\n",
    "#                     print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                     clear_output(wait=True)\n",
    "#                 if i % 20 == 0:\n",
    "#                     elapsed_time = time.time() - start\n",
    "#                     sys.stdout.write('\\r%d [%d/%d] time: %d分%d秒' % (t,min((i * args.batch_size),test_size), test_size, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                     sys.stdout.flush()\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        propotion_arr_TTA += propotion_arr\n",
    "    print()\n",
    "    propotion_arr_TTA /= args.tta\n",
    "    return propotion_arr_TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_only_threthold(propotion_arr, labels_arr, sample_num = 10000, tta_num=None):\n",
    "    start = time.time()\n",
    "    \n",
    "\n",
    "    pc = deepcopy(propotion_arr)\n",
    "    lc = deepcopy(labels_arr)\n",
    "    pc = np.reshape(pc,-1)\n",
    "    lc = np.reshape(lc,-1)\n",
    "    idx = np.argsort(pc)\n",
    "    pc = pc[idx]\n",
    "    lc = lc[idx]\n",
    "\n",
    "    TP = np.sum(labels_arr==1, axis=1)\n",
    "    FN = np.zeros_like(TP)\n",
    "    FP = np.sum(labels_arr==0, axis=1)\n",
    "    TN = np.zeros_like(TP)\n",
    "\n",
    "    f2 = np.zeros_like(TP)\n",
    "\n",
    "    tmp_max = 0\n",
    "    max_thr = 0\n",
    "    pos = 0\n",
    "    for i, thr in enumerate(np.linspace(10**-3,1,sample_num)):\n",
    "        if i % 10 == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "#             print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "        while pos < len(pc) and pc[pos] < thr:\n",
    "            if lc[pos] == 0:\n",
    "                FP[idx[pos] // num_classes] -= 1\n",
    "                TN[idx[pos] // num_classes] += 1\n",
    "            else:\n",
    "                TP[idx[pos] // num_classes] -= 1\n",
    "                FN[idx[pos] // num_classes] += 1\n",
    "#             if pos % 100000 == 0: \n",
    "#                 elapsed_time = time.time() - start\n",
    "#                 if tta_num: print(tta_num)\n",
    "#                 print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                 print('\\r[%d/%d]' % (pos//1000, len(pc)//1000))\n",
    "#                 clear_output(wait=True)\n",
    "            pos += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f2_arr = 5*(precision * recall) / (4*precision + recall)\n",
    "        f2_arr[np.isnan(f2_arr)] = 0\n",
    "        f2 = np.mean(f2_arr)\n",
    "        if f2 > tmp_max:\n",
    "            tmp_max = f2\n",
    "            max_thr = thr\n",
    "    return max_thr, tmp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.mode == 'train':\n",
    "    torch.manual_seed(1)\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        train(epoch, writer)\n",
    "        eval(epoch, writer)\n",
    "        torch.save(model.state_dict(), weight_path + '_epoch' + str(epoch)+'.pkl')\n",
    "        if args.lr_tuned:\n",
    "            scheduler.step()\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode == 'test':\n",
    "    pred = predict(0.17074707470747075)\n",
    "    pred_str = list()\n",
    "    for lst in pred:\n",
    "        pred_str.append(\" \".join(list(map(str, lst))))\n",
    "\n",
    "    submit_df.index = submit_df.index.map(lambda x:x.rstrip(\".png\"))\n",
    "    submit_df.attribute_ids = pred_str\n",
    "\n",
    "    submit_df.to_csv(\"submission.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
