{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import models\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "ON_KAGGLE: bool = 'KAGGLE_WORKING_DIR' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('save_name')\n",
    "arg('model', choices=['resnet34','resnet50', 'resnet101', 'resnet152', 'vgg16_bn', 'resnext101'])\n",
    "arg('cuda')\n",
    "arg('mode', choices=['train', 'eval'])\n",
    "arg('valid_fold', type=int, choices=[0,1,2,3,4])\n",
    "arg('image_size', type=int)\n",
    "arg('--loss', choices=['BCE', 'FL'], default='BCE')\n",
    "arg('--pos_weight', type=int, default=1)\n",
    "arg('--use_tuned_pos_weight', action='store_true')\n",
    "arg('--no_pretrained', action='store_true')\n",
    "arg('--batch-size', type=int, default=50)\n",
    "arg('--epochs', type=int, default=50)\n",
    "arg('--tta', type=int, default=1)\n",
    "arg('--n_workers', type=int, default=3)\n",
    "arg('--lr', type=float, default=0.0001)\n",
    "arg('--verbose', action='store_true')\n",
    "arg('--lr_tuned', action='store_true')\n",
    "arg('--lr_dec_rate', type=int, default=2)\n",
    "args = parser.parse_args(args=['b','resnext101','cuda','train','1','328','--use_tuned_pos_weight','--batch-size', '10','--tta','8','--n_workers','5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file, GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "log_dir =  runs/b\n",
      "weight save path =  ./model_weight/b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb13d140710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path = \"../input/kaggle-imet-2019/\" if ON_KAGGLE else \"/home/sano/Datasets/iMet_Colelction_2019/input/\"\n",
    "\n",
    "log_dir = 'runs/' + args.save_name\n",
    "weight_path = './model_weight/' + args.save_name\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "print('log_dir = ', log_dir)\n",
    "print('weight save path = ', weight_path)\n",
    "\n",
    "torch.manual_seed(823)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "num_classes = 1103\n",
    "extract_attribute = 5 # 予測した上位何個を属性として出力するか\n",
    "\n",
    "models_dict = {'resnet34'  : models.resnet34,\n",
    "               'resnet50'  : models.resnet50,\n",
    "               'resnet101' : models.resnet101,\n",
    "               'resnet152' : models.resnet152,\n",
    "               'vgg16_bn'  : models.vgg16_bn,\n",
    "               'resnext101': models.resnext101_32x8d\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.pos_weight * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iMetsDataset(data.Dataset):\n",
    " \n",
    "    def __init__(self, df, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (dataframe): ファイル名がindex、Nhot_LabelsカラムにNhot化したラベルを格納したDataframe\n",
    "            root_dir (string): 対象の画像ファイルが入っているフォルダ\n",
    "            transform (callable, optional): 施す変換\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "#         if type(idx) == torch.Tensor:\n",
    "#             idx = idx.item()\n",
    "        img_name = os.path.join(self.root_dir, self.df.index[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.mode == 'train':\n",
    "            label = self.df.iloc[idx].Nhot_Labels.astype('float32')\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "def Nhot_encoding(arr, l):\n",
    "    \"\"\"\n",
    "    Nhotエンコーディングを行う\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        ラベル\n",
    "    l : int\n",
    "        総ラベル数\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        ret = np.zeros(l,dtype='int')\n",
    "        ret[arr] = 1\n",
    "        return ret\n",
    "    else:\n",
    "        lst = list()\n",
    "        for i,_ in enumerate(arr):\n",
    "            lst.extend([i] * arr.shape[1])\n",
    "            \n",
    "        ret = np.zeros((arr.shape[0],l),dtype='int')\n",
    "        ret[lst,arr.flatten()] = 1\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = pd.read_csv(load_path + 'labels.csv')\n",
    "label_name = label_name.set_index(\"attribute_id\")\n",
    "submit_df = pd.read_csv(load_path + 'sample_submission.csv')\n",
    "submit_df[\"id\"] = submit_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "submit_df = submit_df.set_index('id')\n",
    "test_size = len(submit_df)\n",
    "\n",
    "train_df = pd.read_csv(load_path + 'train.csv')\n",
    "train_size = len(train_df)\n",
    "train_df[\"attribute_ids\"] = train_df[\"attribute_ids\"].apply(lambda x: np.array([int(s) for s in x.split(\" \")]))\n",
    "train_df[\"Nhot_Labels\"] = train_df[\"attribute_ids\"].apply(lambda x: Nhot_encoding(x,1103))\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "\n",
    "np.random.seed(823)\n",
    "fold = pd.Series(np.arange(len(train_df)) % 5)\n",
    "np.random.shuffle(fold)\n",
    "train_df['fold'] = fold\n",
    "del fold\n",
    "\n",
    "\n",
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "ds_allTrain = iMetsDataset(train_df,load_path+'train',mode ='train')\n",
    "\n",
    "\n",
    "# ds_train, ds_valid = data.random_split(ds_allTrain, [90000, 19237])\n",
    "ds_train = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] != args.valid_fold)[0]) \n",
    "ds_valid = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] == args.valid_fold)[0]) \n",
    "ds_train.dataset = deepcopy(ds_allTrain)\n",
    "\n",
    "\n",
    "ds_test = iMetsDataset(submit_df,load_path+'test', mode='test')\n",
    "\n",
    "\n",
    "\n",
    "ds_train.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size*2,args.image_size*2)),\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "\n",
    "if args.tta == 1:\n",
    "    ds_valid.dataset.transform = transforms.Compose([\n",
    "                                    transforms.Resize((args.image_size, args.image_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(\n",
    "                                        [0.485, 0.456, 0.406], \n",
    "                                        [0.229, 0.224, 0.225]\n",
    "                                    )\n",
    "                                ])\n",
    "else:\n",
    "    ds_valid.dataset.transform = ds_train.dataset.transform\n",
    "\n",
    "\n",
    "ds_test.transform = ds_valid.dataset.transform\n",
    "#                           transforms.Compose([\n",
    "#                                 transforms.Resize((args.image_size, args.image_size)),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(\n",
    "#                                     [0.485, 0.456, 0.406], \n",
    "#                                     [0.229, 0.224, 0.225]\n",
    "#                                 ),\n",
    "#                             ])\n",
    "\n",
    "\n",
    "if type(ds_train.indices) == torch.Tensor:\n",
    "    ds_train.indices = ds_train.indices.numpy()\n",
    "    ds_valid.indices = ds_valid.indices.numpy()\n",
    "\n",
    "\n",
    "dataloader_train = data.DataLoader(dataset=ds_train,batch_size=batch_size,shuffle=True,num_workers=args.n_workers)\n",
    "dataloader_valid = data.DataLoader(dataset=ds_valid,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)\n",
    "dataloader_test = data.DataLoader(dataset=ds_test,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate frequency of attributes and bias_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_attribute = Counter()\n",
    "for i in train_df.attribute_ids:\n",
    "    cnt_attribute.update(i)\n",
    "\n",
    "freq_attr = np.asarray(cnt_attribute.most_common())\n",
    "\n",
    "bias_pos_weight = np.zeros(num_classes)\n",
    "bias_pos_weight[freq_attr[:,0]] = (len(dataloader_train.dataset) / 2) / freq_attr[:,1]\n",
    "bias_pos_weight[bias_pos_weight>100] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "model = models_dict[args.model](pretrained=not args.no_pretrained)\n",
    "\n",
    "if args.model.startswith('resne'):\n",
    "    num_features = model.fc.in_features\n",
    "    features = list(model.fc.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.fc = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "elif args.model.startswith('vgg'):\n",
    "    num_features = model.classifier[-1].in_features\n",
    "    features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "model.load_state_dict(torch.load('model_weight/ResNext101_lrt_p2t4BCE328_rrcflno_f1_epoch16.pkl',map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == 'BCE':\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "elif args.loss == 'FL':\n",
    "    criterion = FocalLoss(gamma=2, logits=True, pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "\n",
    "if args.use_tuned_pos_weight:\n",
    "    criterion.pos_weight = torch.from_numpy(bias_pos_weight)\n",
    "\n",
    "criterion.pos_weight = criterion.pos_weight.float().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25, 30, 35, 40, 45], gamma=1/args.lr_dec_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train,eval,predictの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "def train(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    steps = len(ds_train)//batch_size\n",
    "    for step, (images, labels) in enumerate(dataloader_train, 1):\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % (len(dataloader_train.dataset) // (60 * args.batch_size)) == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.10f, time: %d分%d秒' % (epoch, args.epochs, step, steps, loss.item(), elapsed_time//60, int(elapsed_time % 60)))\n",
    "            writer.add_scalar('train/train_loss', loss.item() , global_step)\n",
    "            \n",
    "def eval(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    # TTA topN\n",
    "#     propotion_arr, labels_arr = pred_prop()\n",
    "    pred_labels_topN = Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-extract_attribute:], num_classes)\n",
    "    f2 = fbeta_score(labels_arr, pred_labels_topN, beta=2 ,average='samples')\n",
    "    precision = precision_score(labels_arr,pred_labels_topN,average='samples')\n",
    "    recall = recall_score(labels_arr,pred_labels_topN,average='samples')\n",
    "    print(\"Val Acc(topN)   : %.10f\" % f2)\n",
    "    print(\"precision(topN) : %.10f\" % precision)\n",
    "    print(\"recall(topN)    : %.10f\" % recall)\n",
    "\n",
    "    \n",
    "    thr, max_f2 = make_only_threthold(np.mean(propotion_arr,axis=0),labels_arr)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\"elapsed_time: %d分%d秒\" % (elapsed_time//60, int(elapsed_time % 60)))\n",
    "    \n",
    "    pred_top10 = np.mean(propotion_arr,axis=0) * Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-7:], num_classes)\n",
    "#     pred_labels = np.mean(propotion_arr,axis=0) > thr\n",
    "    pred_labels = pred_top10 > thr\n",
    "    pred_labels = np.mean(propotion_arr,axis=0) > thr\n",
    "    f2 = fbeta_score(labels_arr,pred_labels, beta=2 ,average='samples')\n",
    "    precision = precision_score(labels_arr,pred_labels,average='samples')\n",
    "    recall = recall_score(labels_arr,pred_labels,average='samples')\n",
    "    print(\"Val Acc   : %.10f\" % f2)\n",
    "    print(\"precision : %.10f\" % precision)\n",
    "    print(\"recall    : %.10f\" % recall)\n",
    "        \n",
    "#     writer.add_scalar('eval/val_acc', f2*100, epoch)\n",
    "#     writer.add_scalar('eval/precision', precision*100, epoch)\n",
    "#     writer.add_scalar('eval/recall', recall*100, epoch)\n",
    "    \n",
    "    return thr\n",
    "    \n",
    "\n",
    "def predict(thr, dataloader=dataloader_test):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    \n",
    "    for i in range(5):\n",
    "        model.load_state_dict(torch.load('../input/imets-resnext101-fold5-tta8/ResNext101_lrt_p2t10BCE328_rrcflrono_f0_epoch26.pkl',map_location=device))\n",
    "        model = model.to(device)\n",
    "        propotion_arr_TTA += pred_prop()\n",
    "        \n",
    "    propotion_arr_TTA /= 5\n",
    "    \n",
    "    \n",
    "    pred_top9 = propotion_arr_TTA * Nhot_encoding(np.argsort(propotion_arr_TTA, axis=1)[:,-9:], num_classes)\n",
    "#     pred_labels = propotion_arr_TTA > thr\n",
    "    pred_labels = pred_top9 > thr\n",
    "    pos, label = np.where(pred_labels==1)\n",
    "    \n",
    "    pred_attr = list()\n",
    "    for i in range(len(dataloader_test.dataset)):\n",
    "        pred_attr.append(label[pos==i])\n",
    "    return pred_attr\n",
    "\n",
    "\n",
    "def pred_prop(dataloader = dataloader_valid):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((args.tta,steps, num_classes))\n",
    "    \n",
    "    for t in range(args.tta):\n",
    "        if t==0:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        if t==1:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        else:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "#                                 transforms.Resize((args.image_size,args.image_size)),\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "#         if t==5:\n",
    "#             ds_valid.dataset.transform = transforms.Compose([\n",
    "# #                                 transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "# #                                 transforms.RandomHorizontalFlip(p=1),\n",
    "# #                                 transforms.RandomRotation((-20,20)),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(\n",
    "#                                     [0.485, 0.456, 0.406], \n",
    "#                                     [0.229, 0.224, 0.225]\n",
    "#                                 ),\n",
    "#                             ])\n",
    "            \n",
    "            \n",
    "        print(dataloader.dataset.dataset.transform)\n",
    "    \n",
    "        print(t, end=' ')\n",
    "        propotion_arr = list()\n",
    "        labels_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "                labels_arr.extend(labels)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "#                 if i % 10 == 0:\n",
    "#                     elapsed_time = time.time() - start\n",
    "#                     print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                     clear_output(wait=True)\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        labels_arr = np.asarray(labels_arr)\n",
    "        propotion_arr_TTA[t] += propotion_arr\n",
    "    print()\n",
    "#     propotion_arr_TTA /= args.tta\n",
    "    \n",
    "    return propotion_arr_TTA, labels_arr\n",
    "\n",
    "\n",
    "def pred_test(dataloader=dataloader_test):\n",
    "    for t in range(args.tta):\n",
    "        if t==0:\n",
    "            ds_test.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        if t==1:\n",
    "            ds_test.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        else:\n",
    "            ds_test.transform = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        print(t, end=' ')\n",
    "        propotion_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, images in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "#                 if i % 10 == 0:\n",
    "#                     elapsed_time = time.time() - start\n",
    "#                     print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                     clear_output(wait=True)\n",
    "#                 if i % 20 == 0:\n",
    "#                     elapsed_time = time.time() - start\n",
    "#                     sys.stdout.write('\\r%d [%d/%d] time: %d分%d秒' % (t,min((i * args.batch_size),test_size), test_size, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                     sys.stdout.flush()\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        propotion_arr_TTA += propotion_arr\n",
    "    print()\n",
    "    propotion_arr_TTA /= args.tta\n",
    "    return propotion_arr_TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_only_threthold(propotion_arr, labels_arr, sample_num = 10000, tta_num=None):\n",
    "    start = time.time()\n",
    "    \n",
    "#     model.eval()\n",
    "#     steps = len(ds_valid)\n",
    "#     propotion_arr = list()\n",
    "#     labels_arr = list()\n",
    "\n",
    "#     # ラベル確率を推論\n",
    "#     with torch.no_grad():\n",
    "#         for i, (images, labels) in enumerate(dataloader_valid,1):\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.cpu().detach().numpy()\n",
    "#             labels_arr.extend(labels)\n",
    "#             outputs = torch.sigmoid(model(images))\n",
    "#             outputs = outputs.cpu().detach().numpy()\n",
    "#             propotion_arr.extend(outputs)\n",
    "#         #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "#         #         for attr in outputs_topN:\n",
    "#         #             pred_attr.append(attr)\n",
    "#             if i % 10 == 0:\n",
    "#                 elapsed_time = time.time() - start\n",
    "#                 print('\\r[%d/%d], time: %d分%d秒' % (min((i * batch_size),steps), steps, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                 clear_output(wait=True)\n",
    "\n",
    "\n",
    "#     propotion_arr = np.asarray(propotion_arr)\n",
    "#     labels_arr = np.asarray(labels_arr)\n",
    "\n",
    "    pc = deepcopy(propotion_arr)\n",
    "    lc = deepcopy(labels_arr)\n",
    "    pc = np.reshape(pc,-1)\n",
    "    lc = np.reshape(lc,-1)\n",
    "    idx = np.argsort(pc)\n",
    "    pc = pc[idx]\n",
    "    lc = lc[idx]\n",
    "\n",
    "    TP = np.sum(labels_arr==1, axis=1)\n",
    "    FN = np.zeros_like(TP)\n",
    "    FP = np.sum(labels_arr==0, axis=1)\n",
    "    TN = np.zeros_like(TP)\n",
    "\n",
    "    f2 = np.zeros_like(TP)\n",
    "\n",
    "    tmp_max = 0\n",
    "    max_thr = 0\n",
    "    pos = 0\n",
    "    for i, thr in enumerate(np.linspace(10**-3,1,sample_num)):\n",
    "        if i % 10 == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "#             print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "        while pos < len(pc) and pc[pos] < thr:\n",
    "            if lc[pos] == 0:\n",
    "                FP[idx[pos] // num_classes] -= 1\n",
    "                TN[idx[pos] // num_classes] += 1\n",
    "            else:\n",
    "                TP[idx[pos] // num_classes] -= 1\n",
    "                FN[idx[pos] // num_classes] += 1\n",
    "#             if pos % 100000 == 0: \n",
    "#                 elapsed_time = time.time() - start\n",
    "#                 if tta_num: print(tta_num)\n",
    "#                 print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                 print('\\r[%d/%d]' % (pos//1000, len(pc)//1000))\n",
    "#                 clear_output(wait=True)\n",
    "            pos += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f2_arr = 5*(precision * recall) / (4*precision + recall)\n",
    "        f2_arr[np.isnan(f2_arr)] = 0\n",
    "        f2 = np.mean(f2_arr)\n",
    "        if f2 > tmp_max:\n",
    "            tmp_max = f2\n",
    "            max_thr = thr\n",
    "    return max_thr, tmp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time: 0分0秒\n",
      "Val Acc   : 0.6107742800\n",
      "precision : 0.4718086504\n",
      "recall    : 0.6894960056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19252745274527452"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(0,SummaryWriter,pa,la,143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(epoch, writer,propotion_arr, labels_arr,num):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    # TTA topN\n",
    "#     propotion_arr, labels_arr = pred_prop()\n",
    "#     pred_labels_topN = Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-extract_attribute:], num_classes)\n",
    "#     f2 = fbeta_score(labels_arr, pred_labels_topN, beta=2 ,average='samples')\n",
    "#     precision = precision_score(labels_arr,pred_labels_topN,average='samples')\n",
    "#     recall = recall_score(labels_arr,pred_labels_topN,average='samples')\n",
    "#     print(\"Val Acc(topN)   : %.10f\" % f2)\n",
    "#     print(\"precision(topN) : %.10f\" % precision)\n",
    "#     print(\"recall(topN)    : %.10f\" % recall)\n",
    "\n",
    "    thr = 0.19252745274527452\n",
    "#     thr, max_f2 = make_only_threthold(np.mean(propotion_arr,axis=0),labels_arr)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\"elapsed_time: %d分%d秒\" % (elapsed_time//60, int(elapsed_time % 60)))\n",
    "    \n",
    "    pred_top10 = np.mean(propotion_arr,axis=0) * Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-num:], num_classes)\n",
    "    pred_labels = pred_top10 > thr\n",
    "#     pred_labels[:,freq_attr[-100:,0]] = 0\n",
    "    \n",
    "#     pred_labels = np.mean(propotion_arr,axis=0) > thr\n",
    "    f2 = fbeta_score(labels_arr,pred_labels, beta=2 ,average='samples')\n",
    "    precision = precision_score(labels_arr,pred_labels,average='samples')\n",
    "    recall = recall_score(labels_arr,pred_labels,average='samples')\n",
    "    print(\"Val Acc   : %.10f\" % f2)\n",
    "    print(\"precision : %.10f\" % precision)\n",
    "    print(\"recall    : %.10f\" % recall)\n",
    "        \n",
    "#     writer.add_scalar('eval/val_acc', f2*100, epoch)\n",
    "#     writer.add_scalar('eval/precision', precision*100, epoch)\n",
    "#     writer.add_scalar('eval/recall', recall*100, epoch)\n",
    "    \n",
    "    return thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11629490034141463\n",
      "Val Acc   : 0.1162949003\n",
      "precision : 0.0326684005, time: 3分54秒\n",
      "recall    : 0.3743850633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4e7b3d39937d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_epoch'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-24deb41b77cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, writer)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(1)\n",
    "# writer = SummaryWriter(log_dir)\n",
    " \n",
    "# for epoch in range(1, args.epochs+1):\n",
    "#     train(epoch, writer)\n",
    "#     eval(epoch, writer)\n",
    "#     torch.save(model.state_dict(), weight_path + '_epoch' + str(epoch)+'.pkl')\n",
    "#     if args.lr_tuned:\n",
    "#         scheduler.step()\n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = predict()\n",
    "# pred_str = list()\n",
    "# for lst in pred:\n",
    "#     pred_str.append(\" \".join(list(map(str, lst))))\n",
    "\n",
    "# submit_df.index = submit_df.index.map(lambda x:x.rstrip(\".png\"))\n",
    "# submit_df.attribute_ids = pred_str\n",
    "\n",
    "# submit_df.to_csv(\"submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
