{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6049a482d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import models\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# data_path = \"~/Datasets/iMet_Colelction_2019\"\n",
    "load_path = \"~/Datasets/iMet_Colelction_2019/input/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "\n",
    "\n",
    "# 複数GPU使用宣言\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net) # make parallel\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iMetsDataset(data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    " \n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (dataframe): ファイル名がindex、Nhot_LabelsカラムにNhot化したラベルを格納したDataframe\n",
    "            root_dir (string): 対象の画像ファイルが入っているフォルダ\n",
    "            transform (callable, optional): 施す変換\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "#         print(self.root_dir)\n",
    "#         print(self.df.index)\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.df.index[idx])\n",
    "        image = Image.fromarray(io.imread(img_name))\n",
    "        label = self.df.iloc[idx].Nhot_Labels.astype('float32')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nhot_encoding(arr, l):\n",
    "    \"\"\"\n",
    "    Nhotエンコーディングを行う\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        ラベル\n",
    "    l : int\n",
    "        総ラベル数\n",
    "    \"\"\"\n",
    "    ret = np.zeros(l,dtype='int')\n",
    "    ret[arr] = 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_classes = 1103\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_name = pd.read_csv(load_path + 'labels.csv')\n",
    "sample = pd.read_csv(load_path + 'sample_submission.csv')\n",
    "train_df = pd.read_csv(load_path + 'train.csv')\n",
    "train_size = len(train_df)\n",
    "\n",
    "train_df[\"attribute_ids\"] = train_df[\"attribute_ids\"].apply(lambda x: np.array([int(s) for s in x.split(\" \")]))\n",
    "train_df[\"Nhot_Labels\"] = train_df[\"attribute_ids\"].apply(lambda x: Nhot_encoding(x,1103))\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットとデータローダの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット\n",
    "train_ds = iMetsDataset(train_df,load_path+'train',\n",
    "                            transform = transforms.Compose([\n",
    "                            transforms.Resize((224,224)),\n",
    "                            transforms.ToTensor(),\n",
    "                            ])\n",
    "                        )\n",
    "\n",
    "# データローダ\n",
    "dataloader_train = data.DataLoader(dataset=train_ds,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ds[0][0])\n",
    "\n",
    "print(train_ds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
