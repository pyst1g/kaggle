{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import models\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "ON_KAGGLE: bool = 'KAGGLE_WORKING_DIR' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('save_name')\n",
    "arg('model', choices=['resnet34','resnet50', 'resnet101', 'resnet152', 'vgg16_bn'])\n",
    "arg('cuda')\n",
    "arg('mode', choices=['train', 'eval'])\n",
    "arg('valid_fold', type=int, choices=[0,1,2,3,4])\n",
    "arg('image_size', type=int)\n",
    "arg('--loss', choices=['BCE', 'FL'], default='BCE')\n",
    "arg('--pos_weight', type=int, default=1)\n",
    "arg('--use_tuned_pos_weight', action='store_true')\n",
    "arg('--no_pretrained', action='store_true')\n",
    "arg('--batch-size', type=int, default=50)\n",
    "arg('--epochs', type=int, default=50)\n",
    "arg('--tta', type=int, default=1)\n",
    "arg('--n_workers', type=int, default=3)\n",
    "arg('--lr', type=float, default=0.0001)\n",
    "args = parser.parse_args(args=['a','resnet34','cuda','train','0','288','--use_tuned_pos_weight','--batch-size', '10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file, GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "log_dir =  runs/a\n",
      "weight save path =  ./model_weight/a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa7de220a30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path = \"../input/kaggle-imet-2019/\" if ON_KAGGLE else \"/home/sano/Datasets/iMet_Colelction_2019/input/\"\n",
    "\n",
    "log_dir = 'runs/' + args.save_name\n",
    "weight_path = './model_weight/' + args.save_name\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "print('log_dir = ', log_dir)\n",
    "print('weight save path = ', weight_path)\n",
    "\n",
    "torch.manual_seed(823)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "num_classes = 1103\n",
    "extract_attribute = 5 # 予測した上位何個を属性として出力するか\n",
    "\n",
    "models_dict = {'resnet34'  : models.resnet34,\n",
    "               'resnet50'  : models.resnet50,\n",
    "               'resnet101' : models.resnet101,\n",
    "               'resnet152' : models.resnet152,\n",
    "               'vgg16_bn'  : models.vgg16_bn}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.pos_weight * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iMetsDataset(data.Dataset):\n",
    " \n",
    "    def __init__(self, df, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (dataframe): ファイル名がindex、Nhot_LabelsカラムにNhot化したラベルを格納したDataframe\n",
    "            root_dir (string): 対象の画像ファイルが入っているフォルダ\n",
    "            transform (callable, optional): 施す変換\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "#         if type(idx) == torch.Tensor:\n",
    "#             idx = idx.item()\n",
    "        img_name = os.path.join(self.root_dir, self.df.index[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.mode == 'train':\n",
    "            label = self.df.iloc[idx].Nhot_Labels.astype('float32')\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "def Nhot_encoding(arr, l):\n",
    "    \"\"\"\n",
    "    Nhotエンコーディングを行う\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        ラベル\n",
    "    l : int\n",
    "        総ラベル数\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        ret = np.zeros(l,dtype='int')\n",
    "        ret[arr] = 1\n",
    "        return ret\n",
    "    else:\n",
    "        lst = list()\n",
    "        for i,_ in enumerate(arr):\n",
    "            lst.extend([i] * arr.shape[1])\n",
    "            \n",
    "        ret = np.zeros((arr.shape[0],l),dtype='int')\n",
    "        ret[lst,arr.flatten()] = 1\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = pd.read_csv(load_path + 'labels.csv')\n",
    "label_name = label_name.set_index(\"attribute_id\")\n",
    "submit_df = pd.read_csv(load_path + 'sample_submission.csv')\n",
    "submit_df[\"id\"] = submit_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "submit_df = submit_df.set_index('id')\n",
    "test_size = len(submit_df)\n",
    "\n",
    "train_df = pd.read_csv(load_path + 'train.csv')\n",
    "train_size = len(train_df)\n",
    "train_df[\"attribute_ids\"] = train_df[\"attribute_ids\"].apply(lambda x: np.array([int(s) for s in x.split(\" \")]))\n",
    "train_df[\"Nhot_Labels\"] = train_df[\"attribute_ids\"].apply(lambda x: Nhot_encoding(x,1103))\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "\n",
    "np.random.seed(823)\n",
    "fold = pd.Series(np.arange(len(train_df)) % 5)\n",
    "np.random.shuffle(fold)\n",
    "train_df['fold'] = fold\n",
    "del fold\n",
    "\n",
    "\n",
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "ds_allTrain = iMetsDataset(train_df,load_path+'train',mode ='train')\n",
    "\n",
    "\n",
    "# ds_train, ds_valid = data.random_split(ds_allTrain, [90000, 19237])\n",
    "ds_train = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] != args.valid_fold)[0]) \n",
    "ds_valid = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] == args.valid_fold)[0]) \n",
    "ds_train.dataset = deepcopy(ds_allTrain)\n",
    "\n",
    "\n",
    "ds_test = iMetsDataset(submit_df,load_path+'test', mode='test')\n",
    "\n",
    "\n",
    "\n",
    "ds_train.dataset.transform = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "\n",
    "if args.tta == 1:\n",
    "    ds_valid.dataset.transform = transforms.Compose([\n",
    "                                    transforms.Resize((args.image_size, args.image_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(\n",
    "                                        [0.485, 0.456, 0.406], \n",
    "                                        [0.229, 0.224, 0.225]\n",
    "                                    )\n",
    "                                ])\n",
    "else:\n",
    "    ds_valid.dataset.transform = ds_train.dataset.transform\n",
    "\n",
    "\n",
    "ds_test.transform = ds_valid.dataset.transform\n",
    "#                           transforms.Compose([\n",
    "#                                 transforms.Resize((args.image_size, args.image_size)),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(\n",
    "#                                     [0.485, 0.456, 0.406], \n",
    "#                                     [0.229, 0.224, 0.225]\n",
    "#                                 ),\n",
    "#                             ])\n",
    "\n",
    "\n",
    "if type(ds_train.indices) == torch.Tensor:\n",
    "    ds_train.indices = ds_train.indices.numpy()\n",
    "    ds_valid.indices = ds_valid.indices.numpy()\n",
    "\n",
    "\n",
    "dataloader_train = data.DataLoader(dataset=ds_train,batch_size=batch_size,shuffle=True,num_workers=args.n_workers)\n",
    "dataloader_valid = data.DataLoader(dataset=ds_valid,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)\n",
    "dataloader_test = data.DataLoader(dataset=ds_test,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate frequency of attributes and bias_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_attribute = Counter()\n",
    "for i in train_df.attribute_ids:\n",
    "    cnt_attribute.update(i)\n",
    "\n",
    "freq_attr = np.asarray(cnt_attribute.most_common())\n",
    "\n",
    "bias_pos_weight = np.zeros(num_classes)\n",
    "bias_pos_weight[freq_attr[:,0]] = (len(dataloader_train.dataset) / 2) / freq_attr[:,1]\n",
    "bias_pos_weight[bias_pos_weight>100] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/sano/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 87306240/87306240 [00:00<00:00, 94661716.72it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "model = models_dict[args.model](pretrained=not args.no_pretrained)\n",
    "\n",
    "if args.model.startswith('resnet'):\n",
    "    num_features = model.fc.in_features\n",
    "    features = list(model.fc.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.fc = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "elif args.model.startswith('vgg'):\n",
    "    num_features = model.classifier[-1].in_features\n",
    "    features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "    \n",
    "# model.load_state_dict(torch.load('model_weight/resnet152/resnet152_FocalLoss_epoch7.pkl'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == 'BCE':\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "elif args.loss == 'FL':\n",
    "    criterion = FocalLoss(gamma=2, logits=True, pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "\n",
    "if args.use_tuned_pos_weight:\n",
    "    criterion.pos_weight = torch.from_numpy(bias_pos_weight)\n",
    "\n",
    "criterion.pos_weight = criterion.pos_weight.float().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train,eval,predictの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "def train(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    steps = len(ds_train)//batch_size\n",
    "    for step, (images, labels) in enumerate(dataloader_train, 1):\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % (len(dataloader_train.dataset) // (60 * args.batch_size)) == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.10f, time: %d分%d秒' % (epoch, args.epochs, step, steps, loss.item(), elapsed_time//60, int(elapsed_time % 60)))\n",
    "            writer.add_scalar('train/train_loss', loss.item() , global_step)\n",
    "\n",
    "            \n",
    "def eval(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    fbeta_lst = list()\n",
    "    precision_lst = list()\n",
    "    recall_lst = list()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader_valid):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.cpu().detach().numpy()\n",
    "            outputs = torch.sigmoid(model(images))\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            outputs_topN_Nhots = Nhot_encoding(outputs_topN, num_classes)\n",
    "            fbeta_lst.append(fbeta_score(labels,outputs_topN_Nhots, beta=2 ,average='samples'))\n",
    "            precision_lst.append(precision_score(labels,outputs_topN_Nhots,average='samples'))\n",
    "            recall_lst.append(recall_score(labels,outputs_topN_Nhots,average='samples'))\n",
    "            \n",
    "    elapsed_time = time.time() - start\n",
    "    print(\"Val Acc   : %.10f\" % (sum(fbeta_lst)/len(fbeta_lst)))\n",
    "    print(\"precision : %.10f, time: %d分%d秒\" % (sum(precision_lst)/len(precision_lst), elapsed_time//60, int(elapsed_time % 60)))\n",
    "    print(\"recall    : %.10f\" % (sum(recall_lst)/len(recall_lst)))\n",
    "    writer.add_scalar('eval/val_acc', sum(fbeta_lst)*100/len(fbeta_lst), epoch)\n",
    "    writer.add_scalar('eval/precision', sum(precision_lst)*100/len(precision_lst), epoch)\n",
    "    writer.add_scalar('eval/recall', sum(recall_lst)*100/len(recall_lst), epoch)\n",
    "    \n",
    "\n",
    "def predict():\n",
    "    pred_attr = list()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(dataloader_test,1):\n",
    "            images = images.to(device)\n",
    "            outputs = torch.sigmoid(model(images))\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            for attr in outputs_topN:\n",
    "                pred_attr.append(attr)\n",
    "            if i % 10 == 0:\n",
    "                sys.stdout.write('\\r[%d/%d]' % (min((i * batch_size),test_size), test_size))\n",
    "                sys.stdout.flush()\n",
    "    return pred_attr          \n",
    "\n",
    "\n",
    "def pred_prop(dataloader = dataloader_valid):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    \n",
    "    for t in range(args.tta):\n",
    "        propotion_arr = list()\n",
    "        labels_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "                labels_arr.extend(labels)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "                if i % 10 == 0:\n",
    "                    elapsed_time = time.time() - start\n",
    "                    print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "                    clear_output(wait=True)\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        labels_arr = np.asarray(labels_arr)\n",
    "        propotion_arr_TTA += propotion_arr\n",
    "    \n",
    "    propotion_arr_TTA /= args.tta\n",
    "    \n",
    "    return propotion_arr_TTA, labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_only_threthold(propotion_arr, labels_arr, sample_num = 10000, tta_num=None):\n",
    "    start = time.time()\n",
    "    \n",
    "#     model.eval()\n",
    "#     steps = len(ds_valid)\n",
    "#     propotion_arr = list()\n",
    "#     labels_arr = list()\n",
    "\n",
    "#     # ラベル確率を推論\n",
    "#     with torch.no_grad():\n",
    "#         for i, (images, labels) in enumerate(dataloader_valid,1):\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.cpu().detach().numpy()\n",
    "#             labels_arr.extend(labels)\n",
    "#             outputs = torch.sigmoid(model(images))\n",
    "#             outputs = outputs.cpu().detach().numpy()\n",
    "#             propotion_arr.extend(outputs)\n",
    "#         #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "#         #         for attr in outputs_topN:\n",
    "#         #             pred_attr.append(attr)\n",
    "#             if i % 10 == 0:\n",
    "#                 elapsed_time = time.time() - start\n",
    "#                 print('\\r[%d/%d], time: %d分%d秒' % (min((i * batch_size),steps), steps, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                 clear_output(wait=True)\n",
    "\n",
    "\n",
    "#     propotion_arr = np.asarray(propotion_arr)\n",
    "#     labels_arr = np.asarray(labels_arr)\n",
    "\n",
    "    pc = deepcopy(propotion_arr)\n",
    "    lc = deepcopy(labels_arr)\n",
    "    pc = np.reshape(pc,-1)\n",
    "    lc = np.reshape(lc,-1)\n",
    "    idx = np.argsort(pc)\n",
    "    pc = pc[idx]\n",
    "    lc = lc[idx]\n",
    "\n",
    "    TP = np.sum(labels_arr==1, axis=1)\n",
    "    FN = np.zeros_like(TP)\n",
    "    FP = np.sum(labels_arr==0, axis=1)\n",
    "    TN = np.zeros_like(TP)\n",
    "\n",
    "    f2 = np.zeros_like(TP)\n",
    "\n",
    "    tmp_max = 0\n",
    "    max_thr = 0\n",
    "    pos = 0\n",
    "    for i, thr in enumerate(np.linspace(10**-3,1,sample_num)):\n",
    "        if i % 10 == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "#             print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "        while pos < len(pc) and pc[pos] < thr:\n",
    "            if lc[pos] == 0:\n",
    "                FP[idx[pos] // num_classes] -= 1\n",
    "                TN[idx[pos] // num_classes] += 1\n",
    "            else:\n",
    "                TP[idx[pos] // num_classes] -= 1\n",
    "                FN[idx[pos] // num_classes] += 1\n",
    "            if pos % 100000 == 0: \n",
    "                elapsed_time = time.time() - start\n",
    "                if tta_num: print(tta_num)\n",
    "                print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "                print('\\r[%d/%d]' % (pos//1000, len(pc)//1000))\n",
    "                clear_output(wait=True)\n",
    "            pos += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f2_arr = 5*(precision * recall) / (4*precision + recall)\n",
    "        f2_arr[np.isnan(f2_arr)] = 0\n",
    "        f2 = np.mean(f2_arr)\n",
    "        if f2 > tmp_max:\n",
    "            tmp_max = f2\n",
    "            max_thr = thr\n",
    "    return max_thr, tmp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)\n",
    "# writer = SummaryWriter(log_dir)\n",
    " \n",
    "# for epoch in range(1, args.epochs+1):\n",
    "#     train(epoch, writer)\n",
    "# #     eval(epoch, writer)\n",
    "#     propotion_arr, labels_arr = pred_prop()\n",
    "#     thr, f2 = make_only_threthold(propotion_arr,labels_arr)\n",
    "    \n",
    "#     torch.save(model.state_dict(), weight_path + '_epoch' + str(epoch)+'.pkl')\n",
    "    \n",
    "\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a479751d521e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_epoch'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-6c98abee70c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, writer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/pytorch/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "writer = SummaryWriter(log_dir)\n",
    " \n",
    "for epoch in range(1, args.epochs+1):\n",
    "    train(epoch, writer)\n",
    "    eval(epoch, writer)\n",
    "    torch.save(model.state_dict(), weight_path + '_epoch' + str(epoch)+'.pkl')\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = predict()\n",
    "# pred_str = list()\n",
    "# for lst in pred:\n",
    "#     pred_str.append(\" \".join(list(map(str, lst))))\n",
    "\n",
    "# submit_df.index = submit_df.index.map(lambda x:x.rstrip(\".png\"))\n",
    "# submit_df.attribute_ids = pred_str\n",
    "\n",
    "# submit_df.to_csv(\"submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
