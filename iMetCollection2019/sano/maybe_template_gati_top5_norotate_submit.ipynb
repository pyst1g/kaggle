{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.metrics import confusion_matrix, f1_score, fbeta_score, precision_score, recall_score\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import models\n",
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "ON_KAGGLE: bool = 'KAGGLE_WORKING_DIR' in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "arg = parser.add_argument\n",
    "arg('save_name')\n",
    "arg('model', choices=['resnet34','resnet50', 'resnet101', 'resnet152', 'vgg16_bn', 'resnext101'])\n",
    "arg('cuda')\n",
    "arg('mode', choices=['train', 'test'])\n",
    "arg('valid_fold', type=int, choices=[0,1,2,3,4])\n",
    "arg('image_size', type=int)\n",
    "arg('--loss', choices=['BCE', 'FL'], default='BCE')\n",
    "arg('--pos_weight', type=int, default=1)\n",
    "arg('--use_tuned_pos_weight', action='store_true')\n",
    "arg('--no_pretrained', action='store_true')\n",
    "arg('--batch-size', type=int, default=50)\n",
    "arg('--epochs', type=int, default=50)\n",
    "arg('--tta', type=int, default=1)\n",
    "arg('--n_workers', type=int, default=3)\n",
    "arg('--lr', type=float, default=0.0001)\n",
    "arg('--verbose', action='store_true')\n",
    "arg('--lr_tuned', action='store_true')\n",
    "arg('--lr_dec_rate', type=int, default=2)\n",
    "args = parser.parse_args(args=['b','resnext101','cuda:1','test','0','328','--use_tuned_pos_weight','--batch-size', '50','--tta','8','--n_workers','5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file, GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:1\n",
      "log_dir =  runs/b\n",
      "weight save path =  ./model_weight/b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f75a45cbf10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path = \"../input/kaggle-imet-2019/\" if ON_KAGGLE else \"/home/sano/Datasets/iMet_Colelction_2019/input/\"\n",
    "\n",
    "log_dir = 'runs/' + args.save_name\n",
    "weight_path = './model_weight/' + args.save_name\n",
    "\n",
    "device = torch.device(args.cuda)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device\", device)\n",
    "print('log_dir = ', log_dir)\n",
    "print('weight save path = ', weight_path)\n",
    "\n",
    "torch.manual_seed(823)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "num_classes = 1103\n",
    "extract_attribute = 5 # 予測した上位何個を属性として出力するか\n",
    "\n",
    "models_dict = {'resnet34'  : models.resnet34,\n",
    "               'resnet50'  : models.resnet50,\n",
    "               'resnet101' : models.resnet101,\n",
    "               'resnet152' : models.resnet152,\n",
    "               'vgg16_bn'  : models.vgg16_bn,\n",
    "               'resnext101': models.resnext101_32x8d\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.pos_weight * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iMetsDataset(data.Dataset):\n",
    " \n",
    "    def __init__(self, df, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (dataframe): ファイル名がindex、Nhot_LabelsカラムにNhot化したラベルを格納したDataframe\n",
    "            root_dir (string): 対象の画像ファイルが入っているフォルダ\n",
    "            transform (callable, optional): 施す変換\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "#         if type(idx) == torch.Tensor:\n",
    "#             idx = idx.item()\n",
    "        img_name = os.path.join(self.root_dir, self.df.index[idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.mode == 'train':\n",
    "            label = self.df.iloc[idx].Nhot_Labels.astype('float32')\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "def Nhot_encoding(arr, l):\n",
    "    \"\"\"\n",
    "    Nhotエンコーディングを行う\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : ndarray\n",
    "        ラベル\n",
    "    l : int\n",
    "        総ラベル数\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        ret = np.zeros(l,dtype='int')\n",
    "        ret[arr] = 1\n",
    "        return ret\n",
    "    else:\n",
    "        lst = list()\n",
    "        for i,_ in enumerate(arr):\n",
    "            lst.extend([i] * arr.shape[1])\n",
    "            \n",
    "        ret = np.zeros((arr.shape[0],l),dtype='int')\n",
    "        ret[lst,arr.flatten()] = 1\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = pd.read_csv(load_path + 'labels.csv')\n",
    "label_name = label_name.set_index(\"attribute_id\")\n",
    "submit_df = pd.read_csv(load_path + 'sample_submission.csv')\n",
    "submit_df[\"id\"] = submit_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "submit_df = submit_df.set_index('id')\n",
    "test_size = len(submit_df)\n",
    "\n",
    "train_df = pd.read_csv(load_path + 'train.csv')\n",
    "train_size = len(train_df)\n",
    "train_df[\"attribute_ids\"] = train_df[\"attribute_ids\"].apply(lambda x: np.array([int(s) for s in x.split(\" \")]))\n",
    "train_df[\"Nhot_Labels\"] = train_df[\"attribute_ids\"].apply(lambda x: Nhot_encoding(x,1103))\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(lambda x: x + \".png\")\n",
    "\n",
    "np.random.seed(823)\n",
    "fold = pd.Series(np.arange(len(train_df)) % 5)\n",
    "np.random.shuffle(fold)\n",
    "train_df['fold'] = fold\n",
    "del fold\n",
    "\n",
    "\n",
    "train_df = train_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "ds_allTrain = iMetsDataset(train_df,load_path+'train',mode ='train')\n",
    "\n",
    "\n",
    "# ds_train, ds_valid = data.random_split(ds_allTrain, [90000, 19237])\n",
    "ds_train = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] != args.valid_fold)[0]) \n",
    "ds_valid = data.Subset(dataset=ds_allTrain, indices=np.where(train_df['fold'] == args.valid_fold)[0]) \n",
    "ds_train.dataset = deepcopy(ds_allTrain)\n",
    "\n",
    "\n",
    "ds_test = iMetsDataset(submit_df,load_path+'test', mode='test')\n",
    "\n",
    "\n",
    "\n",
    "ds_train.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size*2,args.image_size*2)),\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "\n",
    "if args.tta == 1:\n",
    "    ds_valid.dataset.transform = transforms.Compose([\n",
    "                                    transforms.Resize((args.image_size, args.image_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(\n",
    "                                        [0.485, 0.456, 0.406], \n",
    "                                        [0.229, 0.224, 0.225]\n",
    "                                    )\n",
    "                                ])\n",
    "else:\n",
    "    ds_valid.dataset.transform = ds_train.dataset.transform\n",
    "\n",
    "\n",
    "ds_test.transform = ds_valid.dataset.transform\n",
    "#                           transforms.Compose([\n",
    "#                                 transforms.Resize((args.image_size, args.image_size)),\n",
    "#                                 transforms.ToTensor(),\n",
    "#                                 transforms.Normalize(\n",
    "#                                     [0.485, 0.456, 0.406], \n",
    "#                                     [0.229, 0.224, 0.225]\n",
    "#                                 ),\n",
    "#                             ])\n",
    "\n",
    "\n",
    "if type(ds_train.indices) == torch.Tensor:\n",
    "    ds_train.indices = ds_train.indices.numpy()\n",
    "    ds_valid.indices = ds_valid.indices.numpy()\n",
    "\n",
    "\n",
    "dataloader_train = data.DataLoader(dataset=ds_train,batch_size=batch_size,shuffle=True,num_workers=args.n_workers)\n",
    "dataloader_valid = data.DataLoader(dataset=ds_valid,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)\n",
    "dataloader_test = data.DataLoader(dataset=ds_test,batch_size=batch_size,shuffle=False,num_workers=args.n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate frequency of attributes and bias_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_attribute = Counter()\n",
    "for i in train_df.attribute_ids:\n",
    "    cnt_attribute.update(i)\n",
    "\n",
    "freq_attr = np.asarray(cnt_attribute.most_common())\n",
    "\n",
    "bias_pos_weight = np.zeros(num_classes)\n",
    "bias_pos_weight[freq_attr[:,0]] = (len(dataloader_train.dataset) / 2) / freq_attr[:,1]\n",
    "bias_pos_weight[bias_pos_weight>100] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(823)\n",
    "np.random.seed(823)\n",
    "\n",
    "model = models_dict[args.model](pretrained=not args.no_pretrained)\n",
    "\n",
    "if args.model.startswith('resne'):\n",
    "    num_features = model.fc.in_features\n",
    "    features = list(model.fc.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.fc = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "elif args.model.startswith('vgg'):\n",
    "    num_features = model.classifier[-1].in_features\n",
    "    features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, num_classes)]) # Add our layer\n",
    "    model.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "\n",
    "model.load_state_dict(torch.load('model_weight/ResNext101_lrt_p2t10BCE328_rrcflrono_f0_epoch26.pkl',map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.loss == 'BCE':\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "elif args.loss == 'FL':\n",
    "    criterion = FocalLoss(gamma=2, logits=True, pos_weight=torch.from_numpy(np.ones(num_classes) * args.pos_weight))\n",
    "\n",
    "if args.use_tuned_pos_weight:\n",
    "    criterion.pos_weight = torch.from_numpy(bias_pos_weight)\n",
    "\n",
    "criterion.pos_weight = criterion.pos_weight.float().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25, 30, 35, 40, 45], gamma=1/args.lr_dec_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train,eval,predictの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "def train(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    steps = len(ds_train)//batch_size\n",
    "    for step, (images, labels) in enumerate(dataloader_train, 1):\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % (len(dataloader_train.dataset) // (60 * args.batch_size)) == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.10f, time: %d分%d秒' % (epoch, args.epochs, step, steps, loss.item(), elapsed_time//60, int(elapsed_time % 60)))\n",
    "            writer.add_scalar('train/train_loss', loss.item() , global_step)\n",
    "            \n",
    "def eval(epoch, writer):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    # TTA topN\n",
    "    propotion_arr_TTA, labels_arr = pred_prop()\n",
    "#     pred_labels_topN = Nhot_encoding(np.argsort(np.mean(propotion_arr,axis=0), axis=1)[:,-extract_attribute:], num_classes)\n",
    "#     f2 = fbeta_score(labels_arr, pred_labels_topN, beta=2 ,average='samples')\n",
    "#     precision = precision_score(labels_arr,pred_labels_topN,average='samples')\n",
    "#     recall = recall_score(labels_arr,pred_labels_topN,average='samples')\n",
    "#     print(\"Val Acc(topN)   : %.10f\" % f2)\n",
    "#     print(\"precision(topN) : %.10f\" % precision)\n",
    "#     print(\"recall(topN)    : %.10f\" % recall)\n",
    "\n",
    "    \n",
    "    thr, max_f2 = make_only_threthold(propotion_arr_TTA,labels_arr)\n",
    "    elapsed_time = time.time() - start\n",
    "    print(\"elapsed_time: %d分%d秒\" % (elapsed_time//60, int(elapsed_time % 60)))\n",
    "    \n",
    "    if args.verbose:\n",
    "        for t in range(args.tta):\n",
    "            pred_labels = np.mean(propotion_arr[:t+1],axis=0) > thr\n",
    "            f2 = fbeta_score(labels_arr,pred_labels, beta=2 ,average='samples')\n",
    "            precision = precision_score(labels_arr,pred_labels,average='samples')\n",
    "            recall = recall_score(labels_arr,pred_labels,average='samples')\n",
    "            print('tta ', t)\n",
    "            print(\"Val Acc   : %.10f\" % f2)\n",
    "            print(\"precision : %.10f\" % precision)\n",
    "            print(\"recall    : %.10f\" % recall)\n",
    "    else:\n",
    "        pred_labels = np.mean(propotion_arr,axis=0) > thr\n",
    "        f2 = fbeta_score(labels_arr,pred_labels, beta=2 ,average='samples')\n",
    "        precision = precision_score(labels_arr,pred_labels,average='samples')\n",
    "        recall = recall_score(labels_arr,pred_labels,average='samples')\n",
    "        print(\"Val Acc   : %.10f\" % f2)\n",
    "        print(\"precision : %.10f\" % precision)\n",
    "        print(\"recall    : %.10f\" % recall)\n",
    "        \n",
    "#     writer.add_scalar('eval/val_acc', f2*100, epoch)\n",
    "#     writer.add_scalar('eval/precision', precision*100, epoch)\n",
    "#     writer.add_scalar('eval/recall', recall*100, epoch)\n",
    "    \n",
    "    return thr,propotion_arr, labels_arr\n",
    "    \n",
    "\n",
    "def predict(thr, dataloader=dataloader_test):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    \n",
    "    for t in range(args.tta):\n",
    "        print(t, end=' ')\n",
    "        propotion_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, images in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "#                 if i % 10 == 0:\n",
    "#                     elapsed_time = time.time() - start\n",
    "#                     print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                     clear_output(wait=True)\n",
    "                if i % 20 == 0:\n",
    "                    sys.stdout.write('\\r[%d/%d]' % (min((i * args.batch_size),test_size), test_size))\n",
    "                    sys.stdout.flush()\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        propotion_arr_TTA += propotion_arr\n",
    "    print()\n",
    "    \n",
    "    pred_labels = propotion_arr_TTA > thr\n",
    "    pos, label = np.where(pred_labels==1)\n",
    "    \n",
    "    pred_attr = list()\n",
    "    for i in range(len(dataloader_test.dataset)):\n",
    "        pred_attr.append(label[pos==i])\n",
    "    return pred_attr\n",
    "\n",
    "\n",
    "def pred_prop(dataloader = dataloader_valid):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    steps = len(dataloader.dataset)\n",
    "    propotion_arr_TTA = np.zeros((steps, num_classes))\n",
    "    \n",
    "    for t in range(args.tta):\n",
    "        if t==0:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        if t==1:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.Resize((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "#                                 transforms.RandomHorizontalFlip(p=1),\n",
    "#                                 transforms.RandomRotation((-20,20)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "        else:\n",
    "            ds_valid.dataset.transform = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop((args.image_size,args.image_size)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    [0.485, 0.456, 0.406], \n",
    "                                    [0.229, 0.224, 0.225]\n",
    "                                ),\n",
    "                            ])\n",
    "\n",
    "            \n",
    "        print(dataloader.dataset.dataset.transform)\n",
    "    \n",
    "        print(t, end=' ')\n",
    "        propotion_arr = list()\n",
    "        labels_arr = list()\n",
    "        # ラベル確率を推論\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(dataloader,1):\n",
    "                images = images.to(device)\n",
    "                labels = labels.cpu().detach().numpy()\n",
    "                labels_arr.extend(labels)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                outputs = outputs.cpu().detach().numpy()\n",
    "                propotion_arr.extend(outputs)\n",
    "            #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "            #         for attr in outputs_topN:\n",
    "            #             pred_attr.append(attr)\n",
    "                if i % 10 == 0:\n",
    "                    elapsed_time = time.time() - start\n",
    "                    print('\\r[%d/%d], TTA %d time: %d分%d秒' % (min((i * batch_size),steps), steps, t, elapsed_time//60, int(elapsed_time % 60)))\n",
    "                    clear_output(wait=True)\n",
    "        propotion_arr = np.asarray(propotion_arr)\n",
    "        labels_arr = np.asarray(labels_arr)\n",
    "        propotion_arr_TTA += propotion_arr\n",
    "        elapsed_time = time.time() - start\n",
    "        print('time: %d分%d秒' % (elapsed_time//60, int(elapsed_time % 60)))\n",
    "    print()\n",
    "    propotion_arr_TTA /= args.tta\n",
    "    \n",
    "    return propotion_arr_TTA, labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_only_threthold(propotion_arr, labels_arr, sample_num = 10000, tta_num=None):\n",
    "    start = time.time()\n",
    "    \n",
    "#     model.eval()\n",
    "#     steps = len(ds_valid)\n",
    "#     propotion_arr = list()\n",
    "#     labels_arr = list()\n",
    "\n",
    "#     # ラベル確率を推論\n",
    "#     with torch.no_grad():\n",
    "#         for i, (images, labels) in enumerate(dataloader_valid,1):\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.cpu().detach().numpy()\n",
    "#             labels_arr.extend(labels)\n",
    "#             outputs = torch.sigmoid(model(images))\n",
    "#             outputs = outputs.cpu().detach().numpy()\n",
    "#             propotion_arr.extend(outputs)\n",
    "#         #         outputs_topN = np.argsort(outputs, axis=1)[:,-extract_attribute:]\n",
    "#         #         for attr in outputs_topN:\n",
    "#         #             pred_attr.append(attr)\n",
    "#             if i % 10 == 0:\n",
    "#                 elapsed_time = time.time() - start\n",
    "#                 print('\\r[%d/%d], time: %d分%d秒' % (min((i * batch_size),steps), steps, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                 clear_output(wait=True)\n",
    "\n",
    "\n",
    "#     propotion_arr = np.asarray(propotion_arr)\n",
    "#     labels_arr = np.asarray(labels_arr)\n",
    "\n",
    "    pc = deepcopy(propotion_arr)\n",
    "    lc = deepcopy(labels_arr)\n",
    "    pc = np.reshape(pc,-1)\n",
    "    lc = np.reshape(lc,-1)\n",
    "    idx = np.argsort(pc)\n",
    "    pc = pc[idx]\n",
    "    lc = lc[idx]\n",
    "\n",
    "    TP = np.sum(labels_arr==1, axis=1)\n",
    "    FN = np.zeros_like(TP)\n",
    "    FP = np.sum(labels_arr==0, axis=1)\n",
    "    TN = np.zeros_like(TP)\n",
    "\n",
    "    f2 = np.zeros_like(TP)\n",
    "\n",
    "    tmp_max = 0\n",
    "    max_thr = 0\n",
    "    pos = 0\n",
    "    for i, thr in enumerate(np.linspace(10**-3,1,sample_num)):\n",
    "        if i % 10 == 0:\n",
    "            elapsed_time = time.time() - start\n",
    "#             print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "        while pos < len(pc) and pc[pos] < thr:\n",
    "            if lc[pos] == 0:\n",
    "                FP[idx[pos] // num_classes] -= 1\n",
    "                TN[idx[pos] // num_classes] += 1\n",
    "            else:\n",
    "                TP[idx[pos] // num_classes] -= 1\n",
    "                FN[idx[pos] // num_classes] += 1\n",
    "#             if pos % 100000 == 0: \n",
    "#                 elapsed_time = time.time() - start\n",
    "#                 if tta_num: print(tta_num)\n",
    "#                 print('\\r[%d/%d], time: %d分%d秒' % (i, sample_num, elapsed_time//60, int(elapsed_time % 60)))\n",
    "#                 print('\\r[%d/%d]' % (pos//1000, len(pc)//1000))\n",
    "#                 clear_output(wait=True)\n",
    "            pos += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f2_arr = 5*(precision * recall) / (4*precision + recall)\n",
    "        f2_arr[np.isnan(f2_arr)] = 0\n",
    "        f2 = np.mean(f2_arr)\n",
    "        if f2 > tmp_max:\n",
    "            tmp_max = f2\n",
    "            max_thr = thr\n",
    "    return max_thr, tmp_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[5000/21848], TTA 0 time: 1分15秒\n"
     ]
    }
   ],
   "source": [
    "thr,propotion_arr, labels_arr  = eval(0,SummaryWriter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if args.mode = 'train':\n",
    "#     torch.manual_seed(1)\n",
    "#     writer = SummaryWriter(log_dir)\n",
    "\n",
    "#     for epoch in range(1, args.epochs+1):\n",
    "#         train(epoch, writer)\n",
    "#         eval(epoch, writer)\n",
    "#         torch.save(model.state_dict(), weight_path + '_epoch' + str(epoch)+'.pkl')\n",
    "#         if args.lr_tuned:\n",
    "#             scheduler.step()\n",
    "\n",
    "#     writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.mode = 'test':\n",
    "# pred = predict()\n",
    "# pred_str = list()\n",
    "# for lst in pred:\n",
    "#     pred_str.append(\" \".join(list(map(str, lst))))\n",
    "\n",
    "# submit_df.index = submit_df.index.map(lambda x:x.rstrip(\".png\"))\n",
    "# submit_df.attribute_ids = pred_str\n",
    "\n",
    "# submit_df.to_csv(\"submission.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
